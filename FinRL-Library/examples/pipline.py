import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from datetime import datetime, timedelta
from typing import Dict, Tuple, Any, Optional
import os
import joblib
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class TransformerClassifier(nn.Module):
    """Transformer ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸ (ë¡œë“œìš©)"""
    
    def __init__(self, input_dim, d_model=64, nhead=4, layers=2):
        super().__init__()
        self.input_dim = input_dim
        self.d_model = d_model
        self.nhead = nhead
        self.layers = layers
        
        self.embed = nn.Linear(input_dim, d_model)
        enc = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)
        self.encoder = nn.TransformerEncoder(enc, layers)
        self.head = nn.Linear(d_model, 1)
        
        # ì˜ˆì¸¡ í™•ë¥  ë©”ì„œë“œ ì¶”ê°€
        self.predict_proba = self._predict_proba
    
    def forward(self, x):
        x = self.embed(x)
        x = self.encoder(x)
        return torch.sigmoid(self.head(x[:, -1]))
    
    def _predict_proba(self, x):
        """ì˜ˆì¸¡ í™•ë¥  ë°˜í™˜ (2í´ë˜ìŠ¤ ë¶„ë¥˜ìš©)"""
        with torch.no_grad():
            self.eval()
            prob_positive = self.forward(x).cpu().numpy()
            prob_negative = 1 - prob_positive
            return np.column_stack([prob_negative, prob_positive])

class HierarchicalTradingEnvironment:
    """
    ê³„ì¸µì  ê±°ë˜ í™˜ê²½: RL ì—ì´ì „íŠ¸ê°€ Transformerì™€ ê°ì • ë¶„ì„ ì ìˆ˜ë¥¼ ì°¸ê³ 
    """
    
    def __init__(self, transformer_model_path, market_data, sentiment_data_paths):
        # ëª¨ë¸ ë¡œë“œ
        self.transformer_model = self._load_transformer_model(transformer_model_path)
        
        # ë°ì´í„° ë¡œë“œ
        self.market_data = market_data
        self.sentiment_data = self._load_sentiment_data(sentiment_data_paths)
        
        # ë°ì´í„° ì»¬ëŸ¼ í™•ì¸ ë° ë¡œê¹…
        print(f"ì‹œì¥ ë°ì´í„° ì»¬ëŸ¼: {self.market_data.columns.tolist()}")
        if not self.sentiment_data.empty:
            print(f"ê°ì • ë°ì´í„° ì»¬ëŸ¼: {self.sentiment_data.columns.tolist()}")
        
        # ìƒíƒœ ê³µê°„ ì •ì˜
        self.base_features = 12  # Transformer ì…ë ¥ìš© (ê¸°ë³¸ ì‹œì¥ ë°ì´í„°)
        self.transformer_features = 3  # Transformer ì˜ˆì¸¡ ê´€ë ¨
        self.sentiment_features = 6   # ê°ì • ë¶„ì„ ê´€ë ¨ (Google News + Reddit)
        self.state_dim = self.base_features + self.transformer_features + self.sentiment_features
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™”
        self.scaler = StandardScaler()
        self._fit_scaler()
        
        print(f"í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ: ìƒíƒœ ì°¨ì› = {self.state_dim}")
        print(f"- Transformer ì…ë ¥: {self.base_features}ê°œ í”¼ì²˜")
        print(f"- Transformer ì¶œë ¥: {self.transformer_features}ê°œ í”¼ì²˜")
        print(f"- ê°ì • ë¶„ì„: {self.sentiment_features}ê°œ í”¼ì²˜")
        if not self.sentiment_data.empty:
            print(f"ê°ì • ë°ì´í„° ê¸°ê°„: {self.sentiment_data['date'].min()} ~ {self.sentiment_data['date'].max()}")
    
    def _load_transformer_model(self, model_path):
        """Transformer ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        try:
            # PyTorch 2.6+ í˜¸í™˜ì„±ì„ ìœ„í•´ weights_only=False ì„¤ì •
            loaded_obj = torch.load(model_path, map_location='cpu', weights_only=False)
            
            # ì™„ì „í•œ ëª¨ë¸ ê°ì²´ì¸ ê²½ìš°
            if hasattr(loaded_obj, 'eval'):
                print("âœ… ì™„ì „í•œ ëª¨ë¸ ê°ì²´ ë¡œë“œë¨")
                loaded_obj.eval()
                return loaded_obj
            
            # state_dictë‚˜ OrderedDictì¸ ê²½ìš°
            elif isinstance(loaded_obj, (dict, torch.nn.modules.container.OrderedDict)):
                print("âŒ State dict í˜•íƒœì˜ ëª¨ë¸ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                print("ì™„ì „í•œ ëª¨ë¸ ê°ì²´ë¡œ ì €ì¥ëœ íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
                raise ValueError("State dict í˜•íƒœì˜ ëª¨ë¸ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            else:
                print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ í˜•íƒœ: {type(loaded_obj)}")
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ í˜•íƒœ: {type(loaded_obj)}")
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e
        
    def _load_sentiment_data(self, sentiment_data_paths):
        """ê°ì • ë¶„ì„ ë°ì´í„° ë¡œë“œ ë° ë³‘í•©"""
        sentiment_dfs = []
        
        for path in sentiment_data_paths:
            if os.path.exists(path):
                df = pd.read_csv(path)
                
                # ë°ì´í„° ì •ë¦¬
                if 'date' in df.columns:
                    df['date'] = pd.to_datetime(df['date'])
                elif 'datadate' in df.columns:
                    df['date'] = pd.to_datetime(df['datadate'])
                
                # ì»¬ëŸ¼ëª… í™•ì¸ ë° í†µì¼
                print(f"ê°ì • ë°ì´í„° ì»¬ëŸ¼: {df.columns.tolist()}")
                
                # sentiment_score ì»¬ëŸ¼ì„ positive, negative, neutralë¡œ ë³€í™˜
                if 'sentiment_score' in df.columns:
                    # sentiment_scoreë¥¼ ê¸°ë°˜ìœ¼ë¡œ positive/negative/neutral ìƒì„±
                    df['positive'] = df['sentiment_score'].apply(lambda x: max(0, x))
                    df['negative'] = df['sentiment_score'].apply(lambda x: max(0, -x))
                    df['neutral'] = df['sentiment_score'].apply(lambda x: 1 - abs(x) if abs(x) <= 1 else 0)
                elif not all(col in df.columns for col in ['positive', 'negative', 'neutral']):
                    # í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                    df['positive'] = 0.0
                    df['negative'] = 0.0
                    df['neutral'] = 1.0
                    print(f"ê²½ê³ : ê°ì • ì ìˆ˜ ì»¬ëŸ¼ì´ ì—†ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •")
                
                # íŒŒì¼ëª…ìœ¼ë¡œ ì†ŒìŠ¤ êµ¬ë¶„
                if 'googlenews' in path:
                    df['source'] = 'google_news'
                elif 'reddit' in path:
                    df['source'] = 'reddit'
                else:
                    df['source'] = 'unknown'
                
                sentiment_dfs.append(df)
                print(f"ê°ì • ë°ì´í„° ë¡œë“œ: {path} - {len(df)} í–‰")
            else:
                print(f"ê²½ê³ : íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        
        if sentiment_dfs:
            # ë°ì´í„° ë³‘í•©
            combined_sentiment = pd.concat(sentiment_dfs, ignore_index=True)
            
            # ë‚ ì§œë³„, ì¢…ëª©ë³„ë¡œ ê°ì • ì ìˆ˜ ì§‘ê³„
            sentiment_agg = combined_sentiment.groupby(['date', 'tic', 'source']).agg({
                'positive': 'mean',
                'negative': 'mean',
                'neutral': 'mean'
            }).reset_index()
            
            # í”¼ë²—í•˜ì—¬ ì†ŒìŠ¤ë³„ ê°ì • ì ìˆ˜ ë¶„ë¦¬
            sentiment_pivot = sentiment_agg.pivot_table(
                index=['date', 'tic'], 
                columns='source', 
                values=['positive', 'negative', 'neutral'],
                fill_value=0
            )
            
            # ì»¬ëŸ¼ëª… í‰íƒ„í™”
            sentiment_pivot.columns = ['_'.join(col).strip() for col in sentiment_pivot.columns]
            sentiment_pivot = sentiment_pivot.reset_index()
            
            print(f"ìµœì¢… ê°ì • ë°ì´í„° ì»¬ëŸ¼: {sentiment_pivot.columns.tolist()}")
            
            return sentiment_pivot
        else:
            print("ê²½ê³ : ê°ì • ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
    
    def _fit_scaler(self):
        """ìŠ¤ì¼€ì¼ëŸ¬ í”¼íŒ…"""
        if len(self.market_data) > 0:
            # ê¸°ë³¸ í”¼ì²˜ë“¤ë¡œ ìŠ¤ì¼€ì¼ëŸ¬ í”¼íŒ…
            base_features = ['close', 'roc_10', 'rsi_14', 'macd', 
                           'federal_funds_rate', 'treasury_yield', 
                           'cpi', 'unemployment_rate']
            
            available_features = [f for f in base_features if f in self.market_data.columns]
            if available_features:
                sample_data = self.market_data[available_features].dropna()
                if len(sample_data) > 0:
                    self.scaler.fit(sample_data)
    
    def get_transformer_prediction(self, market_features):
        """Transformer ëª¨ë¸ ì˜ˆì¸¡ (12ê°œ í”¼ì²˜ ì…ë ¥)"""
        try:
            
            # ì…ë ¥ ë°ì´í„° ê²€ì¦
            if len(market_features) == 0:
                print("ê²½ê³ : ì…ë ¥ í”¼ì²˜ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return {
                    'prediction': 0.5,
                    'confidence': 0.0,
                    'signal': 0
                }
            
            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (12ê°œ í”¼ì²˜)
            if len(market_features) < 12:
                # ë¶€ì¡±í•œ í”¼ì²˜ëŠ” 0ìœ¼ë¡œ ì±„ì›€
                market_features = np.pad(market_features, (0, 12 - len(market_features)), 'constant', constant_values=0)
            
            # ì •í™•íˆ 12ê°œ í”¼ì²˜ë§Œ ì‚¬ìš©
            input_features = market_features[:12]
            
            # ëª¨ë¸ì˜ ì…ë ¥ ì°¨ì› í™•ì¸
            expected_input_dim = self.transformer_model.input_dim
            actual_input_dim = len(input_features)
            
            if expected_input_dim != actual_input_dim:
                
                # ê¸´ê¸‰ ëŒ€ì‘: ì°¨ì› ë§ì¶¤
                if expected_input_dim < actual_input_dim:
                    input_features = input_features[:expected_input_dim]
                elif expected_input_dim > actual_input_dim:
                    input_features = np.pad(input_features, (0, expected_input_dim - actual_input_dim), 'constant', constant_values=0)
            
            # í…ì„œ ë³€í™˜
            input_tensor = torch.FloatTensor(input_features).unsqueeze(0).unsqueeze(0)
            
            with torch.no_grad():
                # ë‹¨ê³„ë³„ ì‹¤í–‰ìœ¼ë¡œ ì–´ë””ì„œ ì˜¤ë¥˜ê°€ ë‚˜ëŠ”ì§€ í™•ì¸
                try:
                    # 1. ì„ë² ë”© ë ˆì´ì–´
                    embedded = self.transformer_model.embed(input_tensor)
                    
                    # 2. ì¸ì½”ë”
                    encoded = self.transformer_model.encoder(embedded)
                    
                    # 3. í—¤ë“œ (ë§ˆì§€ë§‰ ë ˆì´ì–´)
                    head_input = encoded[:, -1]  # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ìœ„ì¹˜
                    
                    output = self.transformer_model.head(head_input)
                    
                    # ì‹œê·¸ëª¨ì´ë“œ ì ìš©
                    prediction = torch.sigmoid(output).item()
                    
                except Exception as layer_error:
                    print(f"âŒ ëª¨ë¸ ë ˆì´ì–´ ì‹¤í–‰ ì˜¤ë¥˜: {layer_error}")
                    raise layer_error
                
                # ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬
                confidence = abs(prediction - 0.5) * 2
                
                return {
                    'prediction': float(prediction),
                    'confidence': float(confidence),
                    'signal': 1 if prediction > 0.5 else 0
                }
            
        except Exception as e:
            print(f"âŒ Transformer ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            print(f"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            raise SystemExit(f"Transformer ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
    
    def get_sentiment_features(self, date, ticker):
        """ê°ì • ë¶„ì„ í”¼ì²˜ ì¶”ì¶œ"""
        if self.sentiment_data.empty:
            return np.zeros(6)
        
        # í•´ë‹¹ ë‚ ì§œì˜ ê°ì • ë°ì´í„° ì°¾ê¸°
        sentiment_row = self.sentiment_data[
            (self.sentiment_data['date'] == date) & 
            (self.sentiment_data['tic'] == ticker)
        ]
        
        if len(sentiment_row) == 0:
            # ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œì˜ ë°ì´í„° ì‚¬ìš©
            ticker_data = self.sentiment_data[self.sentiment_data['tic'] == ticker]
            if len(ticker_data) > 0:
                closest_date = ticker_data['date'].iloc[
                    (ticker_data['date'] - pd.to_datetime(date)).abs().argsort()[:1]
                ].iloc[0]
                sentiment_row = ticker_data[ticker_data['date'] == closest_date]
        
        if len(sentiment_row) > 0:
            row = sentiment_row.iloc[0]
            
            # ê°ì • ì ìˆ˜ ì¶”ì¶œ (Google News + Reddit)
            features = []
            
            # Google News ê°ì • ì ìˆ˜ (ì»¬ëŸ¼ëª… ìœ ì—°í•˜ê²Œ ì²˜ë¦¬)
            google_pos = row.get('positive_google_news', 0)
            google_neg = row.get('negative_google_news', 0) 
            google_neu = row.get('neutral_google_news', 0)
            
            # Reddit ê°ì • ì ìˆ˜ (ì»¬ëŸ¼ëª… ìœ ì—°í•˜ê²Œ ì²˜ë¦¬)
            reddit_pos = row.get('positive_reddit', 0)
            reddit_neg = row.get('negative_reddit', 0)
            reddit_neu = row.get('neutral_reddit', 0)
            
            # ë§Œì•½ ì†ŒìŠ¤ë³„ ë¶„ë¦¬ê°€ ì•ˆëœ ê²½ìš°, ì „ì²´ ê°ì • ì ìˆ˜ ì‚¬ìš©
            if google_pos == 0 and google_neg == 0 and reddit_pos == 0 and reddit_neg == 0:
                # ì‚¬ìš© ê°€ëŠ¥í•œ ê°ì • ì ìˆ˜ ì»¬ëŸ¼ ì°¾ê¸°
                available_cols = [col for col in row.index if 'positive' in col or 'negative' in col or 'neutral' in col]
                if available_cols:
                    # ì²« ë²ˆì§¸ ì†ŒìŠ¤ì˜ ê°ì • ì ìˆ˜ë¥¼ Google Newsë¡œ ì‚¬ìš©
                    google_pos = row.get('positive_google_news', row.get('positive_unknown', 0))
                    google_neg = row.get('negative_google_news', row.get('negative_unknown', 0))
                    google_neu = row.get('neutral_google_news', row.get('neutral_unknown', 0))
                    
                    # ë‘ ë²ˆì§¸ ì†ŒìŠ¤ë‚˜ ë™ì¼í•œ ê°’ì„ Redditìœ¼ë¡œ ì‚¬ìš©
                    reddit_pos = row.get('positive_reddit', google_pos)
                    reddit_neg = row.get('negative_reddit', google_neg)
                    reddit_neu = row.get('neutral_reddit', google_neu)
            
            features = [google_pos, google_neg, google_neu, reddit_pos, reddit_neg, reddit_neu]
            
            return np.array(features)
        else:
            return np.zeros(6)
    
    def get_state(self, date, ticker):
        """í™•ì¥ëœ ìƒíƒœ ë²¡í„° ìƒì„±"""
        
        try:
            # 1. ê¸°ë³¸ ì‹œì¥ ë°ì´í„° ì¶”ì¶œ
            base_features = self._get_base_features(date, ticker)
            
            # 2. Transformer ì˜ˆì¸¡
            transformer_result = self.get_transformer_prediction(base_features)
            transformer_features = np.array([
                transformer_result['prediction'],
                transformer_result['confidence'],
                transformer_result['signal']
            ])
            
            # 3. ê°ì • ë¶„ì„ í”¼ì²˜
            sentiment_features = self.get_sentiment_features(date, ticker)
            
            # 4. ì „ì²´ ìƒíƒœ ë²¡í„° ê²°í•©
            full_state = np.concatenate([
                base_features,
                transformer_features,
                sentiment_features
            ])
            
            # 5. ì •ê·œí™”
            try:
                # ê¸°ë³¸ í”¼ì²˜ë§Œ ì •ê·œí™” (ì¶”ê°€ í”¼ì²˜ëŠ” ì´ë¯¸ 0-1 ë²”ìœ„)
                normalized_base = self.scaler.transform(base_features.reshape(1, -1)).flatten()
                full_state = np.concatenate([
                    normalized_base,
                    transformer_features,
                    sentiment_features
                ])
            except:
                pass  # ì •ê·œí™” ì‹¤íŒ¨ì‹œ ì›ë³¸ ì‚¬ìš©
            
            return full_state
            
        except SystemExit:
            # Transformer ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹œìŠ¤í…œ ì¢…ë£Œ
            raise
        except Exception as e:
            print(f"âŒ ìƒíƒœ ìƒì„± ì˜¤ë¥˜ ({date}, {ticker}): {e}")
            print(f"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            raise SystemExit(f"ìƒíƒœ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _get_base_features(self, date, ticker):
        """ê¸°ë³¸ ì‹œì¥ ë°ì´í„° ì¶”ì¶œ (Transformerìš© 12ê°œ í”¼ì²˜)"""
        # ë‚ ì§œ í˜•ì‹ í†µì¼
        if isinstance(date, str):
            date = pd.to_datetime(date)
        
        # ì»¬ëŸ¼ëª… í™•ì¸ (tic ë˜ëŠ” ticker)
        ticker_col = 'tic' if 'tic' in self.market_data.columns else 'ticker'
        
        # í•´ë‹¹ ë‚ ì§œì˜ ì‹œì¥ ë°ì´í„° ì°¾ê¸°
        market_row = self.market_data[
            (pd.to_datetime(self.market_data['date']) == date) & 
            (self.market_data[ticker_col] == ticker)
        ]
        
        if len(market_row) == 0:
            # ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œì˜ ë°ì´í„° ì‚¬ìš©
            ticker_data = self.market_data[self.market_data[ticker_col] == ticker]
            if len(ticker_data) > 0:
                ticker_data['date'] = pd.to_datetime(ticker_data['date'])
                closest_idx = (ticker_data['date'] - date).abs().argsort().iloc[0]
                market_row = ticker_data.iloc[closest_idx:closest_idx+1]
        
        if len(market_row) > 0:
            # ê¸°ë³¸ í”¼ì²˜ ì¶”ì¶œ (ê°€ëŠ¥í•œ í•œ ë§ì€ ì»¬ëŸ¼ ì‚¬ìš©)
            primary_features = [
                'close', 'roc_10', 'rsi_14', 'macd', 
                'federal_funds_rate', 'treasury_yield', 'cpi', 'unemployment_rate'
            ]
            
            # ì¶”ê°€ í”¼ì²˜ (ë°ì´í„°ì— ìˆì„ ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ì»¬ëŸ¼ë“¤)
            additional_features = [
                'open', 'high', 'low', 'volume', 'vwap', 'day_of_week', 
                'month', 'quarter', 'market_cap', 'pe_ratio', 'pb_ratio',
                'dividend_yield', 'beta', 'volatility', 'momentum_1m', 'momentum_3m'
            ]
            
            # ì „ì²´ í”¼ì²˜ ë¦¬ìŠ¤íŠ¸
            all_features = primary_features + additional_features
            
            # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
            available_columns = [col for col in all_features if col in market_row.columns]
            
            if available_columns:
                features = market_row[available_columns].values[0]
                
                # NaN ê°’ ì²˜ë¦¬
                features = np.nan_to_num(features, nan=0.0)
                
                
                # 12ê°œ í”¼ì²˜ë¡œ ë§ì¶¤
                if len(features) < 12:
                    # ë¶€ì¡±í•œ í”¼ì²˜ëŠ” 0ìœ¼ë¡œ ì±„ì›€
                    features = np.pad(features, (0, 12 - len(features)), 'constant', constant_values=0)
                elif len(features) > 12:
                    # ë„˜ì¹˜ëŠ” í”¼ì²˜ëŠ” ìë¦„
                    features = features[:12]
                
                # ê¸°ë³¸ ì •ê·œí™” (ë„ˆë¬´ í° ê°’ ë°©ì§€)
                features = np.clip(features, -1000, 1000)
                
                return features
            else:
                print(f"ê²½ê³ : ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                print(f"ì‹œì¥ ë°ì´í„° ì»¬ëŸ¼: {market_row.columns.tolist()}")
                return np.zeros(12)
        else:
            print(f"ê²½ê³ : í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ ({date}, {ticker})")
            return np.zeros(12)
    
    def step(self, action, date, ticker):
        """í™˜ê²½ ìŠ¤í… ì‹¤í–‰"""
        # í˜„ì¬ ìƒíƒœ
        current_state = self.get_state(date, ticker)
        
        # ë‹¤ìŒ ë‚ ì§œ ê³„ì‚°
        next_date = pd.to_datetime(date) + timedelta(days=1)
        
        # ë‹¤ìŒ ìƒíƒœ
        next_state = self.get_state(next_date, ticker)
        
        # ìˆ˜ìµë¥  ê³„ì‚°
        market_return = self._calculate_return(date, next_date, ticker)
        
        # ë³´ìƒ ê³„ì‚°
        reward = self._calculate_reward(action, market_return, current_state)
        
        # ì¢…ë£Œ ì¡°ê±´
        done = False  # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì—í”¼ì†Œë“œ ì¢…ë£Œ ì¡°ê±´ ì¶”ê°€
        
        return next_state, reward, done
    
    def _calculate_return(self, current_date, next_date, ticker):
        """ìˆ˜ìµë¥  ê³„ì‚°"""
        try:
            current_price = self._get_price(current_date, ticker)
            next_price = self._get_price(next_date, ticker)
            
            if current_price > 0 and next_price > 0:
                return (next_price - current_price) / current_price
            else:
                return 0.0
        except:
            return 0.0
    
    def _get_price(self, date, ticker):
        """íŠ¹ì • ë‚ ì§œì˜ ì£¼ê°€ ê°€ì ¸ì˜¤ê¸°"""
        if isinstance(date, str):
            date = pd.to_datetime(date)
        
        # ì»¬ëŸ¼ëª… í™•ì¸ (tic ë˜ëŠ” ticker)
        ticker_col = 'tic' if 'tic' in self.market_data.columns else 'ticker'
        
        price_row = self.market_data[
            (pd.to_datetime(self.market_data['date']) == date) & 
            (self.market_data[ticker_col] == ticker)
        ]
        
        if len(price_row) > 0:
            return price_row['close'].iloc[0]
        else:
            return 0.0
    
    def _calculate_reward(self, action, market_return, state):
        """í–¥ìƒëœ ë³´ìƒ í•¨ìˆ˜"""
        # ê¸°ë³¸ ìˆ˜ìµë¥  ë³´ìƒ
        base_reward = action * market_return
        
        # ìƒíƒœì—ì„œ ì˜ˆì¸¡ ì •ë³´ ì¶”ì¶œ
        transformer_pred = state[12]      # Transformer ì˜ˆì¸¡ (12ë²ˆì§¸ ì¸ë±ìŠ¤)
        transformer_conf = state[13]      # Transformer í™•ì‹ ë„ (13ë²ˆì§¸ ì¸ë±ìŠ¤)
        transformer_signal = state[14]    # Transformer ì‹ í˜¸ (14ë²ˆì§¸ ì¸ë±ìŠ¤)
        
        # ê°ì • ì ìˆ˜ (Google News + Reddit) - 15ë²ˆì§¸ ì¸ë±ìŠ¤ë¶€í„°
        google_positive = state[15]
        google_negative = state[16]
        reddit_positive = state[18]
        reddit_negative = state[19]
        
        # 1. ë°©í–¥ì„± ì¼ì¹˜ ë³´ë„ˆìŠ¤
        direction_bonus = 0
        if transformer_signal > 0.5 and action > 0:  # ë‘˜ ë‹¤ ìƒìŠ¹
            direction_bonus = 0.1 * transformer_conf
        elif transformer_signal < 0.5 and action < 0:  # ë‘˜ ë‹¤ í•˜ë½
            direction_bonus = 0.1 * transformer_conf
        
        # 2. ê°ì •-í–‰ë™ ì¼ì¹˜ ë³´ë„ˆìŠ¤
        sentiment_bonus = 0
        
        # Google News ê°ì • ê¸°ë°˜
        google_sentiment = google_positive - google_negative
        if google_sentiment > 0.1 and action > 0:
            sentiment_bonus += 0.03
        elif google_sentiment < -0.1 and action < 0:
            sentiment_bonus += 0.03
        
        # Reddit ê°ì • ê¸°ë°˜
        reddit_sentiment = reddit_positive - reddit_negative
        if reddit_sentiment > 0.1 and action > 0:
            sentiment_bonus += 0.02
        elif reddit_sentiment < -0.1 and action < 0:
            sentiment_bonus += 0.02
        
        # 3. í™•ì‹ ë„ ê¸°ë°˜ ì¡°ì •
        confidence_multiplier = transformer_conf
        
        # ìµœì¢… ë³´ìƒ ê³„ì‚°
        enhanced_reward = (
            base_reward * (1 + confidence_multiplier * 0.2) + 
            direction_bonus + 
            sentiment_bonus
        )
        
        return enhanced_reward

class EnhancedTD3Agent:
    """
    í–¥ìƒëœ TD3 ì—ì´ì „íŠ¸
    """
    
    def __init__(self, state_dim, action_dim, max_action):
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.max_action = max_action
        
        # ë„¤íŠ¸ì›Œí¬ ì´ˆê¸°í™”
        self.actor = Actor(state_dim, action_dim, max_action)
        self.critic_1 = Critic(state_dim, action_dim)
        self.critic_2 = Critic(state_dim, action_dim)
        
        # íƒ€ê²Ÿ ë„¤íŠ¸ì›Œí¬
        self.actor_target = Actor(state_dim, action_dim, max_action)
        self.critic_1_target = Critic(state_dim, action_dim)
        self.critic_2_target = Critic(state_dim, action_dim)
        
        # íƒ€ê²Ÿ ë„¤íŠ¸ì›Œí¬ ì´ˆê¸°í™”
        self.actor_target.load_state_dict(self.actor.state_dict())
        self.critic_1_target.load_state_dict(self.critic_1.state_dict())
        self.critic_2_target.load_state_dict(self.critic_2.state_dict())
        
        # ì˜µí‹°ë§ˆì´ì €
        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=3e-4)
        self.critic_1_optimizer = torch.optim.Adam(self.critic_1.parameters(), lr=3e-4)
        self.critic_2_optimizer = torch.optim.Adam(self.critic_2.parameters(), lr=3e-4)
        
        # ë¦¬í”Œë ˆì´ ë²„í¼ (ê°„ë‹¨í•œ êµ¬í˜„)
        self.replay_buffer = ReplayBuffer(100000)
        
        # TD3 í•˜ì´í¼íŒŒë¼ë¯¸í„°
        self.tau = 0.005
        self.policy_noise = 0.2
        self.noise_clip = 0.5
        self.policy_freq = 2
        
        self.total_it = 0
    
    def select_action(self, state, noise=0.1):
        """í–‰ë™ ì„ íƒ"""
        state_tensor = torch.FloatTensor(state.reshape(1, -1))
        action = self.actor(state_tensor).cpu().data.numpy().flatten()
        
        if noise != 0:
            action = action + np.random.normal(0, noise, size=self.action_dim)
            action = action.clip(-self.max_action, self.max_action)
            
        return action
    
    def train(self, batch_size=256):
        """TD3 í›ˆë ¨"""
        if len(self.replay_buffer) < batch_size:
            return
        
        self.total_it += 1
        
        # ë°°ì¹˜ ìƒ˜í”Œë§
        state, action, next_state, reward, done = self.replay_buffer.sample(batch_size)
        
        with torch.no_grad():
            # íƒ€ê²Ÿ ì •ì±… ìŠ¤ë¬´ë”©
            noise = (torch.randn_like(action) * self.policy_noise).clamp(-self.noise_clip, self.noise_clip)
            next_action = (self.actor_target(next_state) + noise).clamp(-self.max_action, self.max_action)
            
            # íƒ€ê²Ÿ Q ê°’ ê³„ì‚°
            target_Q1 = self.critic_1_target(next_state, next_action)
            target_Q2 = self.critic_2_target(next_state, next_action)
            target_Q = torch.min(target_Q1, target_Q2)
            target_Q = reward + (1 - done) * 0.99 * target_Q
        
        # í˜„ì¬ Q ê°’
        current_Q1 = self.critic_1(state, action)
        current_Q2 = self.critic_2(state, action)
        
        # í¬ë¦¬í‹± ì†ì‹¤
        critic_loss = nn.MSELoss()(current_Q1, target_Q) + nn.MSELoss()(current_Q2, target_Q)
        
        # í¬ë¦¬í‹± ì—…ë°ì´íŠ¸
        self.critic_1_optimizer.zero_grad()
        self.critic_2_optimizer.zero_grad()
        critic_loss.backward()
        self.critic_1_optimizer.step()
        self.critic_2_optimizer.step()
        
        # ì§€ì—°ëœ ì •ì±… ì—…ë°ì´íŠ¸
        if self.total_it % self.policy_freq == 0:
            # ì•¡í„° ì†ì‹¤
            actor_loss = -self.critic_1(state, self.actor(state)).mean()
            
            # ì•¡í„° ì—…ë°ì´íŠ¸
            self.actor_optimizer.zero_grad()
            actor_loss.backward()
            self.actor_optimizer.step()
            
            # ì†Œí”„íŠ¸ ì—…ë°ì´íŠ¸
            self.soft_update(self.actor, self.actor_target)
            self.soft_update(self.critic_1, self.critic_1_target)
            self.soft_update(self.critic_2, self.critic_2_target)
    
    def soft_update(self, source, target):
        """ì†Œí”„íŠ¸ ì—…ë°ì´íŠ¸"""
        for target_param, source_param in zip(target.parameters(), source.parameters()):
            target_param.data.copy_(target_param.data * (1.0 - self.tau) + source_param.data * self.tau)

class Actor(nn.Module):
    """ì•¡í„° ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, state_dim, action_dim, max_action):
        super(Actor, self).__init__()
        
        self.l1 = nn.Linear(state_dim, 400)
        self.l2 = nn.Linear(400, 300)
        self.l3 = nn.Linear(300, action_dim)
        
        self.max_action = max_action
        
    def forward(self, state):
        a = torch.relu(self.l1(state))
        a = torch.relu(self.l2(a))
        return self.max_action * torch.tanh(self.l3(a))

class Critic(nn.Module):
    """í¬ë¦¬í‹± ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, state_dim, action_dim):
        super(Critic, self).__init__()
        
        self.l1 = nn.Linear(state_dim + action_dim, 400)
        self.l2 = nn.Linear(400, 300)
        self.l3 = nn.Linear(300, 1)
        
    def forward(self, state, action):
        sa = torch.cat([state, action], 1)
        
        q1 = torch.relu(self.l1(sa))
        q1 = torch.relu(self.l2(q1))
        q1 = self.l3(q1)
        
        return q1

class ReplayBuffer:
    """ë¦¬í”Œë ˆì´ ë²„í¼"""
    
    def __init__(self, capacity):
        self.capacity = capacity
        self.buffer = []
        self.position = 0
    
    def add(self, state, action, next_state, reward, done):
        if len(self.buffer) < self.capacity:
            self.buffer.append(None)
        
        self.buffer[self.position] = (state, action, next_state, reward, done)
        self.position = (self.position + 1) % self.capacity
    
    def sample(self, batch_size):
        batch = np.random.choice(len(self.buffer), batch_size, replace=False)
        state, action, next_state, reward, done = zip(*[self.buffer[i] for i in batch])
        
        return (
            torch.FloatTensor(state),
            torch.FloatTensor(action),
            torch.FloatTensor(next_state),
            torch.FloatTensor(reward),
            torch.FloatTensor(done)
        )
    
    def __len__(self):
        return len(self.buffer)

class HierarchicalTradingSystem:
    """
    ê³„ì¸µì  ê±°ë˜ ì‹œìŠ¤í…œ í†µí•© í´ë˜ìŠ¤
    """
    
    def __init__(self, transformer_model_path, market_data, sentiment_data_paths):
        # í™˜ê²½ ì´ˆê¸°í™”
        self.env = HierarchicalTradingEnvironment(
            transformer_model_path, market_data, sentiment_data_paths
        )
        
        # RL ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        self.agent = EnhancedTD3Agent(
            state_dim=self.env.state_dim,
            action_dim=7,  # 7ê°œ ì¢…ëª©
            max_action=1.0  # ì •ê·œí™”ëœ í–‰ë™ ë²”ìœ„
        )
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_log = []
        
    def train_integrated_system(self, episodes=1000):
        """í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨"""
        
        tickers = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA', 'META', 'NVDA']
        
        try:
            for episode in range(episodes):
                total_reward = 0
                steps = 0
                
                # í›ˆë ¨ ê¸°ê°„ ìƒ˜í”Œë§
                train_dates = self.sample_training_period()
                
                # pandas Seriesë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if isinstance(train_dates, pd.Series):
                    train_dates = train_dates.tolist()
                elif hasattr(train_dates, 'tolist'):
                    train_dates = train_dates.tolist()
                
                # ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ í™•ì¸
                if len(train_dates) < 2:
                    print(f"Episode {episode}: í›ˆë ¨ ë‚ ì§œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue
                
                for i in range(len(train_dates) - 1):  # ë§ˆì§€ë§‰ ë‚  ì œì™¸
                    date = train_dates[i]
                    next_date = train_dates[i + 1]
                    
                    # ê° ì¢…ëª©ë³„ë¡œ ê±°ë˜ ê²°ì •
                    episode_rewards = []
                    
                    for ticker_idx, ticker in enumerate(tickers):
                        try:
                            # í˜„ì¬ ìƒíƒœ íšë“
                            state = self.env.get_state(date, ticker)
                            
                            # í–‰ë™ ì„ íƒ
                            action = self.agent.select_action(state)
                            
                            # í™˜ê²½ ìŠ¤í…
                            next_state, reward, done = self.env.step(action[ticker_idx], date, ticker)
                            
                            # ê²½í—˜ ì €ì¥
                            self.agent.replay_buffer.add(
                                state, action, next_state, reward, done
                            )
                            
                            # í•™ìŠµ
                            if len(self.agent.replay_buffer) > 1000:
                                self.agent.train()
                            
                            total_reward += reward
                            episode_rewards.append(reward)
                            steps += 1
                            
                        except SystemExit:
                            # ì‹¬ê°í•œ ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹œìŠ¤í…œ ì¢…ë£Œ
                            raise
                        except Exception as e:
                            print(f"Episode {episode}, {ticker}, {date}: ì˜¤ë¥˜ ë°œìƒ - {e}")
                            print(f"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            raise SystemExit(f"í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    
                    if len(episode_rewards) == 0:  # ëª¨ë“  ì¢…ëª©ì—ì„œ ì˜¤ë¥˜ ë°œìƒ
                        break
                
                # ì—í”¼ì†Œë“œ ì„±ëŠ¥ ê¸°ë¡
                avg_reward = np.mean(episode_rewards) if episode_rewards else 0
                self.performance_log.append({
                    'episode': episode,
                    'total_reward': total_reward,
                    'avg_reward': avg_reward,
                    'steps': steps
                })
                
                if episode % 100 == 0:
                    print(f"Episode {episode}: Avg Reward = {avg_reward:.4f}, Total Reward = {total_reward:.4f}")
            
            print(f"âœ… í›ˆë ¨ ì™„ë£Œ: {episodes} ì—í”¼ì†Œë“œ")
            
        except SystemExit:
            # ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹ í˜¸ ì¬ì „íŒŒ
            raise
        except Exception as e:
            print(f"âŒ í›ˆë ¨ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            print(f"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            raise SystemExit(f"í›ˆë ¨ ì‹¤íŒ¨: {e}")
    
    def make_trading_decision(self, date, ticker):
        """ì‹¤ì œ ê±°ë˜ ê²°ì •"""
        
        try:
            # í˜„ì¬ ìƒíƒœ íšë“
            state = self.env.get_state(date, ticker)
            
            # RL ì—ì´ì „íŠ¸ í–‰ë™ ì„ íƒ (ë…¸ì´ì¦ˆ ì œê±°)
            action = self.agent.select_action(state, noise=0)
            
            # ì˜ì‚¬ê²°ì • í•´ì„
            decision = self.interpret_action(action[0], state)  # ì²« ë²ˆì§¸ í–‰ë™ë§Œ ì‚¬ìš©
            
            return decision
            
        except SystemExit:
            # ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹ í˜¸ ì¬ì „íŒŒ
            raise
        except Exception as e:
            print(f"âŒ ê±°ë˜ ê²°ì • ì˜¤ë¥˜ ({date}, {ticker}): {e}")
            print(f"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            raise SystemExit(f"ê±°ë˜ ê²°ì • ì‹¤íŒ¨: {e}")
    
    def interpret_action(self, action, state):
        """í–‰ë™ì„ ê±°ë˜ ê²°ì •ìœ¼ë¡œ í•´ì„"""
        
        # ëª¨ë¸ ì˜ˆì¸¡ ì •ë³´ ì¶”ì¶œ (12ê°œ ê¸°ë³¸ í”¼ì²˜ ì´í›„)
        transformer_pred = state[12]
        transformer_conf = state[13]
        transformer_signal = state[14]
        
        # ê°ì • ì ìˆ˜ (15ë²ˆì§¸ ì¸ë±ìŠ¤ë¶€í„°)
        google_sentiment = state[15] - state[16]  # positive - negative
        reddit_sentiment = state[18] - state[19]  # positive - negative
        
        # í–‰ë™ ê°•ë„ ê³„ì‚°
        action_strength = abs(action)
        
        # ì˜ì‚¬ê²°ì • ë¡œì§
        if action_strength < 0.1:
            decision = "HOLD"
            confidence = "LOW"
        elif action > 0:
            decision = "BUY"
            confidence = "HIGH" if action_strength > 0.5 else "MEDIUM"
        else:
            decision = "SELL"
            confidence = "HIGH" if action_strength > 0.5 else "MEDIUM"
        
        return {
            'action': decision,
            'confidence': confidence,
            'quantity': action_strength,
            'reasoning': {
                'transformer_prediction': f"{transformer_pred:.2f}",
                'transformer_confidence': f"{transformer_conf:.2f}",
                'transformer_signal': 'UP' if transformer_signal > 0.5 else 'DOWN',
                'google_sentiment': f"{google_sentiment:.2f}",
                'reddit_sentiment': f"{reddit_sentiment:.2f}",
                'rl_action': f"{action:.2f}"
            }
        }
    
    def sample_training_period(self):
        """í›ˆë ¨ìš© ë‚ ì§œ ìƒ˜í”Œë§"""
        # ì‹¤ì œ ë°ì´í„° ê¸°ê°„ì—ì„œ ìƒ˜í”Œë§
        if len(self.env.market_data) > 0:
            available_dates = pd.to_datetime(self.env.market_data['date']).unique()
            available_dates = pd.Series(available_dates).sort_values()
            
            # 30ì¼ ê¸°ê°„ ì„ íƒ
            if len(available_dates) >= 30:
                start_idx = np.random.randint(0, len(available_dates) - 30)
                selected_dates = available_dates.iloc[start_idx:start_idx + 30]
                return selected_dates.tolist()  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            else:
                return available_dates.tolist()  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        else:
            # ê¸°ë³¸ ê¸°ê°„
            start_date = pd.to_datetime('2020-01-01')
            date_range = pd.date_range(start_date, periods=30, freq='D')
            return date_range.tolist()  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

def load_market_data(file_path):
    """ì‹œì¥ ë°ì´í„° ë¡œë“œ"""
    try:
        data = pd.read_csv(file_path)
        print(f"ì‹œì¥ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {file_path} - {len(data)} í–‰")
        return data
    except Exception as e:
        print(f"ì‹œì¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    transformer_model_path = "/Users/gamjawon/FinRL-Library/examples/models/transformer_classifier.pt"
    market_data_path = "/Users/gamjawon/FinRL-Library/examples/data/merged.csv"
    sentiment_data_paths = [
        "/Users/gamjawon/FinRL-Library/examples/data/M7_googlenews_2020_2022_sentiment_feature.csv",
        "/Users/gamjawon/FinRL-Library/examples/data/M7_reddits_2022_2025_sentiment_feature.csv"
    ]

    print("ğŸ“Š ë°ì´í„° ë° ëª¨ë¸ ë¡œë”© ì¤‘...")

    # ì‹œì¥ ë°ì´í„° ì „ì²´ ë¡œë“œ
    market_data_all = load_market_data(market_data_path)
    market_data_all['date'] = pd.to_datetime(market_data_all['date'])

    # ğŸ”¹ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    train_data = market_data_all[market_data_all['date'] < '2023-07-01'].copy()
    test_data = market_data_all[market_data_all['date'] >= '2023-07-01'].copy()

    print(f"âœ… í›ˆë ¨ ë°ì´í„° ê¸°ê°„: {train_data['date'].min().date()} ~ {train_data['date'].max().date()} ({len(train_data)} rows)")
    print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ê°„: {test_data['date'].min().date()} ~ {test_data['date'].max().date()} ({len(test_data)} rows)")
    
    # Transformer ëª¨ë¸ ê²½ë¡œ í™•ì¸
    if not os.path.exists(transformer_model_path):
        raise FileNotFoundError(f"Transformer ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {transformer_model_path}")
    
    try:
        # í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        trading_system = HierarchicalTradingSystem(
            transformer_model_path, train_data, sentiment_data_paths
        )
        
        print(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - ìƒíƒœ ì°¨ì›: {trading_system.env.state_dim}")
        
        # ì‹œìŠ¤í…œ í›ˆë ¨
        print("\nğŸš€ í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨ ì‹œì‘...")
        trading_system.train_integrated_system(episodes=500)
        
        # ì‹¤ì œ ê±°ë˜ ê²°ì • í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š ê±°ë˜ ê²°ì • í…ŒìŠ¤íŠ¸...")
        
        # í…ŒìŠ¤íŠ¸í•  ë‚ ì§œ (ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ì„ íƒ)
        available_dates = pd.to_datetime(train_data['date']).unique()
        available_dates = sorted(available_dates)
        test_date = available_dates[-10] if len(available_dates) >= 10 else available_dates[-1]
        
        test_tickers = ['AAPL', 'GOOGL', 'TSLA', 'MSFT', 'AMZN']
        
        for ticker in test_tickers:
            try:
                decision = trading_system.make_trading_decision(test_date, ticker)
                print(f"\n{ticker} ê±°ë˜ ê²°ì • ({test_date.strftime('%Y-%m-%d')}):")
                print(f"  ğŸ“ˆ í–‰ë™: {decision['action']}")
                print(f"  ğŸ¯ í™•ì‹ ë„: {decision['confidence']}")
                print(f"  ğŸ“Š ìˆ˜ëŸ‰: {decision['quantity']:.3f}")
                print(f"  ğŸ§  ê·¼ê±°:")
                for key, value in decision['reasoning'].items():
                    print(f"    - {key}: {value}")
                    
            except Exception as e:
                print(f"  âŒ {ticker} ê²°ì • ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ì„±ëŠ¥ ìš”ì•½
        if trading_system.performance_log:
            print("\nğŸ“ˆ í›ˆë ¨ ì„±ëŠ¥ ìš”ì•½:")
            recent_performance = trading_system.performance_log[-50:]  # ìµœê·¼ 50 ì—í”¼ì†Œë“œ
            avg_reward = np.mean([p['avg_reward'] for p in recent_performance])
            print(f"  í‰ê·  ë³´ìƒ (ìµœê·¼ 50 ì—í”¼ì†Œë“œ): {avg_reward:.4f}")
            print(f"  ì´ í›ˆë ¨ ì—í”¼ì†Œë“œ: {len(trading_system.performance_log)}")
        
        # ëª¨ë¸ ì €ì¥
        save_trained_model(trading_system, "trained_hierarchical_model.pth")
        
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

def generate_sample_market_data():
    """ìƒ˜í”Œ ì‹œì¥ ë°ì´í„° ìƒì„±"""
    print("ìƒ˜í”Œ ì‹œì¥ ë°ì´í„° ìƒì„± ì¤‘...")
    
    tickers = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA', 'META', 'NVDA']
    dates = pd.date_range('2020-01-01', '2023-12-31', freq='D')
    
    data = []
    
    for ticker in tickers:
        base_price = np.random.uniform(100, 300)
        
        for i, date in enumerate(dates):
            # ëœë¤ ì›Œí¬ë¡œ ê°€ê²© ìƒì„±
            if i == 0:
                price = base_price
            else:
                price = max(1, price + np.random.normal(0, price * 0.02))
            
            row = {
                'date': date,
                'tic': ticker,
                'close': price,
                'roc_10': np.random.normal(0, 0.05),
                'rsi_14': np.random.uniform(20, 80),
                'macd': np.random.normal(0, 0.1),
                'federal_funds_rate': np.random.uniform(0, 5),
                'treasury_yield': np.random.uniform(1, 4),
                'cpi': np.random.uniform(1, 6),
                'unemployment_rate': np.random.uniform(3, 10)
            }
            data.append(row)
    
    return pd.DataFrame(data)

def create_sample_transformer_model(save_path):
    """ìƒ˜í”Œ Transformer ëª¨ë¸ ìƒì„±"""
    print("ìƒ˜í”Œ Transformer ëª¨ë¸ ìƒì„± ì¤‘...")
    
    class SampleTransformerClassifier(nn.Module):
        def __init__(self, input_dim=13, hidden_dim=64, num_classes=2):
            super().__init__()
            self.fc1 = nn.Linear(input_dim, hidden_dim)
            self.fc2 = nn.Linear(hidden_dim, hidden_dim)
            self.fc3 = nn.Linear(hidden_dim, num_classes)
            self.dropout = nn.Dropout(0.1)
            
        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.dropout(x)
            x = torch.relu(self.fc2(x))
            x = self.dropout(x)
            x = self.fc3(x)
            return x
        
        def predict_proba(self, x):
            with torch.no_grad():
                logits = self.forward(x)
                probs = torch.softmax(logits, dim=1)
                return probs.numpy()
    
    # ëª¨ë¸ ìƒì„± ë° ì €ì¥
    model = SampleTransformerClassifier()
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥
    torch.save(model, save_path)
    print(f"ìƒ˜í”Œ ëª¨ë¸ ì €ì¥: {save_path}")

def save_trained_model(trading_system, save_path):
    """í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥"""
    try:
        model_state = {
            'actor_state_dict': trading_system.agent.actor.state_dict(),
            'critic_1_state_dict': trading_system.agent.critic_1.state_dict(),
            'critic_2_state_dict': trading_system.agent.critic_2.state_dict(),
            'state_dim': trading_system.env.state_dim,
            'action_dim': trading_system.agent.action_dim,
            'performance_log': trading_system.performance_log
        }
        
        torch.save(model_state, save_path)
        print(f"âœ… í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥: {save_path}")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")

def load_trained_model(load_path, transformer_model_path, market_data, sentiment_data_paths, weights_only=False):
    """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        trading_system = HierarchicalTradingSystem(
            transformer_model_path, market_data, sentiment_data_paths
        )
        
        # ì €ì¥ëœ ìƒíƒœ ë¡œë“œ
        checkpoint = torch.load(load_path, map_location='cpu', weights_only=weights_only)
        
        trading_system.agent.actor.load_state_dict(checkpoint['actor_state_dict'])
        trading_system.agent.critic_1.load_state_dict(checkpoint['critic_1_state_dict'])
        trading_system.agent.critic_2.load_state_dict(checkpoint['critic_2_state_dict'])
        
        if 'performance_log' in checkpoint:
            trading_system.performance_log = checkpoint['performance_log']
        
        print(f"âœ… í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ: {load_path}")
        return trading_system
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def evaluate_model_performance(trading_system, test_data, test_period_days=30):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    
    tickers = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']
    
    # í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì„ íƒ
    available_dates = pd.to_datetime(test_data['date']).unique()
    test_dates = available_dates[-test_period_days:] if len(available_dates) >= test_period_days else available_dates
    
    total_returns = []
    decisions_log = []
    
    for date in test_dates:
        daily_returns = []
        
        for ticker in tickers:
            try:
                # ê±°ë˜ ê²°ì •
                decision = trading_system.make_trading_decision(date, ticker)
                
                # ì‹¤ì œ ìˆ˜ìµë¥  ê³„ì‚° (ë‹¤ìŒ ë‚  ê¸°ì¤€)
                current_price = trading_system.env._get_price(date, ticker)
                next_date = date + timedelta(days=1)
                next_price = trading_system.env._get_price(next_date, ticker)
                
                if current_price > 0 and next_price > 0:
                    market_return = (next_price - current_price) / current_price
                    
                    # í¬ì§€ì…˜ì— ë”°ë¥¸ ìˆ˜ìµë¥ 
                    if decision['action'] == 'BUY':
                        position_return = market_return * decision['quantity']
                    elif decision['action'] == 'SELL':
                        position_return = -market_return * decision['quantity']
                    else:  # HOLD
                        position_return = 0
                    
                    daily_returns.append(position_return)
                    
                    decisions_log.append({
                        'date': date,
                        'ticker': ticker,
                        'decision': decision['action'],
                        'quantity': decision['quantity'],
                        'market_return': market_return,
                        'position_return': position_return
                    })
                    
            except Exception as e:
                print(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ({ticker}, {date}): {e}")
        
        if daily_returns:
            total_returns.append(np.mean(daily_returns))
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    if total_returns:
        total_return = np.sum(total_returns)
        avg_daily_return = np.mean(total_returns)
        volatility = np.std(total_returns)
        sharpe_ratio = avg_daily_return / volatility if volatility > 0 else 0
        
        print(f"ğŸ“ˆ í‰ê°€ ê²°ê³¼:")
        print(f"  ì´ ìˆ˜ìµë¥ : {total_return:.4f}")
        print(f"  í‰ê·  ì¼ì¼ ìˆ˜ìµë¥ : {avg_daily_return:.4f}")
        print(f"  ë³€ë™ì„±: {volatility:.4f}")
        print(f"  ìƒ¤í”„ ë¹„ìœ¨: {sharpe_ratio:.4f}")
        print(f"  ê±°ë˜ ê²°ì • ìˆ˜: {len(decisions_log)}")
        
        return {
            'total_return': total_return,
            'avg_daily_return': avg_daily_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'decisions_log': decisions_log
        }
    else:
        print("âŒ ì„±ëŠ¥ í‰ê°€ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return None

if __name__ == "__main__":
    main()