import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from datetime import datetime, timedelta
from typing import Dict, Tuple, Any, Optional
import os
import joblib
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

MAX_HOLDING_DAYS = 100

class TransformerClassifier(nn.Module):
    def __init__(self,input_dim,d_model=64,nhead=4, layers=2):
        super().__init__()
        self.input_dim = input_dim
        self.embed = nn.Linear(input_dim,d_model)
        enc = nn.TransformerEncoderLayer(d_model,nhead,batch_first=True)
        self.encoder = nn.TransformerEncoder(enc,layers)
        self.head = nn.Linear(d_model,1)
    def forward(self,x):
        x = self.embed(x)
        x = self.encoder(x)
        return torch.sigmoid(self.head(x[:,-1]))  # (B,1)

class HierarchicalTradingEnvironment:
    """
    ê³„ì¸µì  ê±°ë˜ í™˜ê²½: RL ì—ì´ì „íŠ¸ê°€ Transformerì™€ ê°ì • ë¶„ì„ ì ìˆ˜ë¥¼ ì°¸ê³ 
    """
    def __init__(self, transformer_model_path, market_data, sentiment_data_paths):
        # ëª¨ë¸ ë¡œë“œ
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.transformer_model = self._load_transformer_model(transformer_model_path)
        
        # ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¡œë“œ
        self.market_data = self._preprocess_market_data(market_data)
        self.sentiment_data = self._load_sentiment_data(sentiment_data_paths)
        
        # í”¼ì²˜ ì •ì˜
        self.feature_cols = self._define_feature_columns()
        
        # ë°ì´í„° ì»¬ëŸ¼ í™•ì¸ ë° ë¡œê¹…
        print(f"ì‹œì¥ ë°ì´í„° ì»¬ëŸ¼: {self.market_data.columns.tolist()}")
        if not self.sentiment_data.empty:
            print(f"ê°ì • ë°ì´í„° ì»¬ëŸ¼: {self.sentiment_data.columns.tolist()}")
        
        # ìƒíƒœ ê³µê°„ ì •ì˜
        self.base_features = len(self.feature_cols)  # ê¸°ë³¸ ì‹œì¥ ë°ì´í„°
        self.transformer_features = 3  # Transformer ì˜ˆì¸¡ ê´€ë ¨
        self.sentiment_features = 6   # ê°ì • ë¶„ì„ ê´€ë ¨ (Google News + Reddit)
        self.state_dim = self.base_features + self.transformer_features + self.sentiment_features
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™”
        self.scaler = StandardScaler()
        self._fit_scaler()
        
        print(f"í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ: ìƒíƒœ ì°¨ì› = {self.state_dim}")
        print(f"- ê¸°ë³¸ í”¼ì²˜: {self.base_features}ê°œ")
        print(f"- Transformer ì¶œë ¥: {self.transformer_features}ê°œ í”¼ì²˜")
        print(f"- ê°ì • ë¶„ì„: {self.sentiment_features}ê°œ í”¼ì²˜")
        if not self.sentiment_data.empty:
            print(f"ê°ì • ë°ì´í„° ê¸°ê°„: {self.sentiment_data['date'].min()} ~ {self.sentiment_data['date'].max()}")
   
    def _preprocess_market_data(self, market_data):
        """ì‹œì¥ ë°ì´í„° ì „ì²˜ë¦¬ (ì›ë³¸ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ)"""
        # 1. ê¸°ë³¸ momentum ë°ì´í„° ì¤€ë¹„ (ROC_10, RSI_14, MACD í¬í•¨)
        momentum_data = market_data[['Date', 'Ticker', 'Close', 'ROC_10', 'RSI_14', 'MACD']].copy()
        momentum_data['Date'] = pd.to_datetime(momentum_data['Date'])
        momentum_data = momentum_data[momentum_data['Date'] >= '2020-01-01'].reset_index(drop=True)
        
        # 2. ê±°ì‹œê²½ì œ ì§€í‘œ ë¡œë“œ ë° ì¼ê°„ ë°ì´í„°ë¡œ ë³€í™˜
        try:
            macro_path = "/Users/gamjawon/prometheus-11team/DATA/technical/macro_indicators_2020_2025-03.csv"
            if os.path.exists(macro_path):
                macro_data = pd.read_csv(macro_path)
                macro_data.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)
                macro_data['Date'] = pd.to_datetime(macro_data['Date'])
                
                # ì¼ê°„ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
                macro_data.set_index('Date', inplace=True)
                daily_index = pd.date_range(start='2020-01-01', end='2025-04-30', freq='D')
                macro_data_daily = macro_data.reindex(daily_index, method='ffill').reset_index().rename(columns={'index': 'Date'})
            else:
                print("ê±°ì‹œê²½ì œ ë°ì´í„°ê°€ ì—†ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •")
                macro_data_daily = pd.DataFrame({'Date': momentum_data['Date'].unique()})
                for col in ['federal_funds_rate', 'treasury_yield', 'cpi', 'unemployment_rate']:
                    macro_data_daily[col] = 0.0
        except Exception as e:
            print(f"ê±°ì‹œê²½ì œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            macro_data_daily = pd.DataFrame({'Date': momentum_data['Date'].unique()})
            for col in ['federal_funds_rate', 'treasury_yield', 'cpi', 'unemployment_rate']:
                macro_data_daily[col] = 0.0
        
        # 3. ì¬ë¬´ ë°ì´í„° ë¡œë“œ ë° ì¼ê°„ ë°ì´í„°ë¡œ ë³€í™˜
        try:
            financial_path = "/Users/gamjawon/prometheus-11team/FinRL-Library/examples/data/M7_financial_data_2020_2025.csv"
            if os.path.exists(financial_path):
                financial_data = pd.read_csv(financial_path)
                
                # íšŒì‚¬ëª…-í‹°ì»¤ ë§¤í•‘
                company_to_ticker = {
                    'Alphabet': 'GOOGL', 'Amazon': 'AMZN', 'Apple': 'AAPL',
                    'Meta': 'META', 'Microsoft': 'MSFT', 'Nvidia': 'NVDA', 'Tesla': 'TSLA'
                }
                financial_data['Ticker'] = financial_data['Company'].map(company_to_ticker)
                financial_data['Date'] = pd.to_datetime(financial_data['Release Date'])
                
                features = ['Operating Income', 'Net Income', 'EPS Diluted', 'Total Assets', 'Shareholders Equity']
                daily_index = pd.date_range(start='2020-01-01', end='2025-04-30', freq='D')
                
                daily_financial_list = []
                for ticker in financial_data['Ticker'].unique():
                    df_t = financial_data.loc[financial_data['Ticker'] == ticker, ['Date', 'Ticker'] + features].copy()
                    df_t = df_t.set_index('Date').sort_index()
                    df_t = df_t[~df_t.index.duplicated(keep='last')]
                    df_t = df_t.reindex(daily_index).ffill()
                    df_t['Ticker'] = ticker
                    df_t = df_t.reset_index().rename(columns={'index': 'Date'})
                    daily_financial_list.append(df_t)
                
                daily_financial_data = pd.concat(daily_financial_list, ignore_index=True)
            else:
                print("ì¬ë¬´ ë°ì´í„°ê°€ ì—†ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •")
                daily_financial_data = momentum_data[['Date', 'Ticker']].copy()
                for col in ['Operating Income', 'Net Income', 'EPS Diluted', 'Total Assets', 'Shareholders Equity']:
                    daily_financial_data[col] = 0.0
        except Exception as e:
            print(f"ì¬ë¬´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            daily_financial_data = momentum_data[['Date', 'Ticker']].copy()
            for col in ['Operating Income', 'Net Income', 'EPS Diluted', 'Total Assets', 'Shareholders Equity']:
                daily_financial_data[col] = 0.0
        
        # 4. ëª¨ë“  ë°ì´í„° ë³‘í•©
        merged_data = pd.merge(momentum_data, macro_data_daily, on='Date', how='left')
        full_merged = pd.merge(merged_data, daily_financial_data, on=['Date', 'Ticker'], how='left')
        
        # 5. Target ìƒì„± ë° ì •ë¦¬ - ìˆ˜ì •ëœ ë²„ì „
        full_merged['Signal'] = ((full_merged['Close'].shift(-5) / full_merged['Close']) - 1 > 0).astype(int)

        # NaN ì²˜ë¦¬ë¥¼ ë” ê´€ëŒ€í•˜ê²Œ
        full_merged = full_merged.dropna(subset=['Close', 'ROC_10', 'RSI_14', 'MACD']).reset_index(drop=True)  # í•µì‹¬ ì»¬ëŸ¼ë§Œ ì²´í¬
        full_merged = full_merged.fillna(0)  # ë‚˜ë¨¸ì§€ NaNì€ 0ìœ¼ë¡œ ì±„ì›€

        print(f"ì „ì²˜ë¦¬ëœ ë°ì´í„° shape: {full_merged.shape}")
        print(f"ìµœì¢… ë°ì´í„° head:")
        print(full_merged.head())
        return full_merged
    
    def _define_feature_columns(self):
        """í”¼ì²˜ ì»¬ëŸ¼ ì •ì˜"""
        all_possible_features = [
            'ROC_10', 'RSI_14', 'MACD', 'federal_funds_rate', 'treasury_yield', 
            'cpi', 'unemployment_rate', 'Operating Income', 'Net Income', 
            'EPS Diluted', 'Total Assets', 'Shareholders Equity'
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        feature_cols = [col for col in all_possible_features if col in self.market_data.columns]
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜: {feature_cols}")
        return feature_cols
    
    def _load_transformer_model(self, model_path):
        """Transformer ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        try:
            model = TransformerClassifier(input_dim=17).to(self.device)
            state_dict = torch.load(model_path, map_location=self.device, weights_only=False)
            model.load_state_dict(state_dict)
            model.eval()
            
            print("âœ… Transformer ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return model
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e
    
    def _fit_scaler(self):
        """ìŠ¤ì¼€ì¼ëŸ¬ í”¼íŒ…"""
        if len(self.market_data) > 0 and len(self.feature_cols) > 0:
            sample_data = self.market_data[self.feature_cols].dropna()
            if len(sample_data) > 0:
                self.scaler.fit(sample_data)
                print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ í”¼íŒ… ì™„ë£Œ: {len(self.feature_cols)}ê°œ í”¼ì²˜")
    
    def get_transformer_prediction(self, market_features):
        """Transformer ëª¨ë¸ ì˜ˆì¸¡ (17ê°œ í”¼ì²˜ ì…ë ¥)"""
        try:
            if len(market_features) == 0:
                return {'prediction': 0.5, 'confidence': 0.0, 'signal': 0}
            
            # 17ê°œ í”¼ì²˜ë¡œ ë§ì¶¤
            if len(market_features) < 17:
                market_features = np.pad(market_features, (0, 17 - len(market_features)), 'constant', constant_values=0)
            elif len(market_features) > 17:
                market_features = market_features[:17]
            
            # í…ì„œ ë³€í™˜ ë° ëª¨ë¸ ì˜ˆì¸¡
            input_tensor = torch.tensor(market_features, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                prediction = self.transformer_model(input_tensor).cpu().numpy().flatten()[0]
                
                confidence = abs(prediction - 0.5) * 2
                signal = 1 if prediction > 0.5 else 0
                
                return {
                    'prediction': float(prediction),
                    'confidence': float(confidence),
                    'signal': signal
                }
            
        except Exception as e:
            print(f"âŒ Transformer ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            raise SystemExit(f"Transformer ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
    
    def _get_base_features(self, date, ticker):
        """ê¸°ë³¸ ì‹œì¥ ë°ì´í„° ì¶”ì¶œ"""
        if isinstance(date, str):
            date = pd.to_datetime(date)
        
        # í•´ë‹¹ ë‚ ì§œì˜ ì‹œì¥ ë°ì´í„° ì°¾ê¸°
        market_row = self.market_data[
            (pd.to_datetime(self.market_data['Date']) == date) & 
            (self.market_data['Ticker'] == ticker)
        ]
        
        if len(market_row) == 0:
            # ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œì˜ ë°ì´í„° ì‚¬ìš©
            ticker_data = self.market_data[self.market_data['Ticker'] == ticker]
            if len(ticker_data) > 0:
                ticker_data['Date'] = pd.to_datetime(ticker_data['Date'])
                closest_idx = (ticker_data['Date'] - date).abs().argsort().iloc[0]
                market_row = ticker_data.iloc[closest_idx:closest_idx+1]
        
        if len(market_row) > 0 and self.feature_cols:
            features = market_row[self.feature_cols].values[0]
            features = np.nan_to_num(features, nan=0.0)
            features = np.clip(features, -1000, 1000)
            return features
        else:
            print(f"ê²½ê³ : í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ ({date}, {ticker})")
            return np.zeros(len(self.feature_cols) if self.feature_cols else 17)
        
    
    def get_state(self, date, ticker):
        """í™•ì¥ëœ ìƒíƒœ ë²¡í„° ìƒì„±"""
        try:
            # 1. ê¸°ë³¸ ì‹œì¥ ë°ì´í„° ì¶”ì¶œ
            base_features = self._get_base_features(date, ticker)
            
            # 2. Transformer ì˜ˆì¸¡
            transformer_result = self.get_transformer_prediction(base_features)
            transformer_features = np.array([
                transformer_result['prediction'],
                transformer_result['confidence'],
                transformer_result['signal']
            ])
            
            # 3. ê°ì • ë¶„ì„ í”¼ì²˜
            sentiment_features = self.get_sentiment_features(date, ticker)
            
            # 4. ì „ì²´ ìƒíƒœ ë²¡í„° ê²°í•©
            full_state = np.concatenate([
                base_features,
                transformer_features,
                sentiment_features
            ])
            
            # 5. ì •ê·œí™” (ê¸°ë³¸ í”¼ì²˜ë§Œ)
            try:
                if len(self.feature_cols) > 0 and len(base_features) >= len(self.feature_cols):
                    normalized_base = self.scaler.transform(base_features[:len(self.feature_cols)].reshape(1, -1)).flatten()
                    
                    if len(base_features) > len(self.feature_cols):
                        remaining_base = base_features[len(self.feature_cols):]
                        normalized_base = np.concatenate([normalized_base, remaining_base])
                    
                    full_state = np.concatenate([
                        normalized_base,
                        transformer_features,
                        sentiment_features
                    ])
            except:
                pass  # ì •ê·œí™” ì‹¤íŒ¨ì‹œ ì›ë³¸ ì‚¬ìš©
            
            return full_state
            
        except SystemExit:
            raise
        except Exception as e:
            print(f"âŒ ìƒíƒœ ìƒì„± ì˜¤ë¥˜ ({date}, {ticker}): {e}")
            raise SystemExit(f"ìƒíƒœ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _load_sentiment_data(self, sentiment_data_paths):
        """ê°ì • ë¶„ì„ ë°ì´í„° ë¡œë“œ ë° ë³‘í•©"""
        sentiment_dfs = []
        
        for path in sentiment_data_paths:
            if os.path.exists(path):
                df = pd.read_csv(path)
                
                # ë°ì´í„° ì •ë¦¬
                if 'date' in df.columns:
                    df['date'] = pd.to_datetime(df['date'])
                elif 'datadate' in df.columns:
                    df['date'] = pd.to_datetime(df['datadate'])
                
                # sentiment_score ì»¬ëŸ¼ì„ positive, negative, neutralë¡œ ë³€í™˜
                if 'sentiment_score' in df.columns:
                    df['positive'] = df['sentiment_score'].apply(lambda x: max(0, x))
                    df['negative'] = df['sentiment_score'].apply(lambda x: max(0, -x))
                    df['neutral'] = df['sentiment_score'].apply(lambda x: 1 - abs(x) if abs(x) <= 1 else 0)
                elif not all(col in df.columns for col in ['positive', 'negative', 'neutral']):
                    df['positive'] = 0.0
                    df['negative'] = 0.0
                    df['neutral'] = 1.0
                
                # íŒŒì¼ëª…ìœ¼ë¡œ ì†ŒìŠ¤ êµ¬ë¶„
                if 'googlenews' in path:
                    df['source'] = 'google_news'
                elif 'reddit' in path:
                    df['source'] = 'reddit'
                else:
                    df['source'] = 'unknown'
                
                sentiment_dfs.append(df)
                print(f"ê°ì • ë°ì´í„° ë¡œë“œ: {path} - {len(df)} í–‰")
            else:
                print(f"ê²½ê³ : íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        
        if sentiment_dfs:
            combined_sentiment = pd.concat(sentiment_dfs, ignore_index=True)
            
            # ë‚ ì§œë³„, ì¢…ëª©ë³„ë¡œ ê°ì • ì ìˆ˜ ì§‘ê³„
            sentiment_agg = combined_sentiment.groupby(['date', 'tic', 'source']).agg({
                'positive': 'mean',
                'negative': 'mean',
                'neutral': 'mean'
            }).reset_index()
            
            # í”¼ë²—í•˜ì—¬ ì†ŒìŠ¤ë³„ ê°ì • ì ìˆ˜ ë¶„ë¦¬
            sentiment_pivot = sentiment_agg.pivot_table(
                index=['date', 'tic'], 
                columns='source', 
                values=['positive', 'negative', 'neutral'],
                fill_value=0
            )
            
            # ì»¬ëŸ¼ëª… í‰íƒ„í™”
            sentiment_pivot.columns = ['_'.join(col).strip() for col in sentiment_pivot.columns]
            sentiment_pivot = sentiment_pivot.reset_index()
            
            print(f"ìµœì¢… ê°ì • ë°ì´í„° ì»¬ëŸ¼: {sentiment_pivot.columns.tolist()}")
            return sentiment_pivot
        else:
            print("ê²½ê³ : ê°ì • ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
    def get_sentiment_features(self, date, ticker):
        """ê°ì • ë¶„ì„ í”¼ì²˜ ì¶”ì¶œ"""
        if self.sentiment_data.empty:
            return np.zeros(6)
        
        # í•´ë‹¹ ë‚ ì§œì˜ ê°ì • ë°ì´í„° ì°¾ê¸°
        sentiment_row = self.sentiment_data[
            (self.sentiment_data['date'] == date) & 
            (self.sentiment_data['tic'] == ticker)
        ]
        
        if len(sentiment_row) == 0:
            # ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œì˜ ë°ì´í„° ì‚¬ìš©
            ticker_data = self.sentiment_data[self.sentiment_data['tic'] == ticker]
            if len(ticker_data) > 0:
                closest_date = ticker_data['date'].iloc[
                    (ticker_data['date'] - pd.to_datetime(date)).abs().argsort()[:1]
                ].iloc[0]
                sentiment_row = ticker_data[ticker_data['date'] == closest_date]
        
        if len(sentiment_row) > 0:
            row = sentiment_row.iloc[0]
            
            # ê°ì • ì ìˆ˜ ì¶”ì¶œ (Google News + Reddit)
            google_pos = row.get('positive_google_news', 0)
            google_neg = row.get('negative_google_news', 0) 
            google_neu = row.get('neutral_google_news', 0)
            
            reddit_pos = row.get('positive_reddit', 0)
            reddit_neg = row.get('negative_reddit', 0)
            reddit_neu = row.get('neutral_reddit', 0)
            
            # ë§Œì•½ ì†ŒìŠ¤ë³„ ë¶„ë¦¬ê°€ ì•ˆëœ ê²½ìš°
            if google_pos == 0 and google_neg == 0 and reddit_pos == 0 and reddit_neg == 0:
                google_pos = row.get('positive_google_news', row.get('positive_unknown', 0))
                google_neg = row.get('negative_google_news', row.get('negative_unknown', 0))
                google_neu = row.get('neutral_google_news', row.get('neutral_unknown', 0))
                
                reddit_pos = row.get('positive_reddit', google_pos)
                reddit_neg = row.get('negative_reddit', google_neg)
                reddit_neu = row.get('neutral_reddit', google_neu)
            
            features = [google_pos, google_neg, google_neu, reddit_pos, reddit_neg, reddit_neu]
            return np.array(features)
        else:
            return np.zeros(6)
    
    def step(self, action_vector, date, ticker):
        """
        í™˜ê²½ ìŠ¤í… ì‹¤í–‰: action_vectorëŠ” [a_1, ..., a_7, holding_action]
        """
        # ë³´ìœ ê¸°ê°„ ì¶”ì¶œ
        raw_holding = action_vector[-1]
        holding_period = int((raw_holding + 1) / 2 * (MAX_HOLDING_DAYS - 1)) + 1

        current_state = self.get_state(date, ticker)
        next_date = pd.to_datetime(date) + timedelta(days=holding_period)
        next_state = self.get_state(next_date, ticker)
        
        # ë³´ìƒ: holding_period ë™ì•ˆì˜ ëˆ„ì  ìˆ˜ìµë¥ 
        reward = self._calculate_holding_reward(date, next_date, ticker, action_vector[0])
        
        done = False
        return next_state, reward, done
    
    def _calculate_holding_reward(self, entry_date, exit_date, ticker, position_action):
        """ë³´ìœ ê¸°ê°„ ë™ì•ˆ ëˆ„ì  ìˆ˜ìµë¥  ê¸°ë°˜ ë³´ìƒ ê³„ì‚°"""
        entry_price = self._get_price(entry_date, ticker)
        exit_price = self._get_price(exit_date, ticker)

        if entry_price > 0 and exit_price > 0:
            return (exit_price / entry_price - 1) * position_action * 10
        else:
            return 0.0
    
    def _calculate_return(self, current_date, next_date, ticker):
        """ìˆ˜ìµë¥  ê³„ì‚°"""
        try:
            current_price = self._get_price(current_date, ticker)
            next_price = self._get_price(next_date, ticker)
            
            if current_price > 0 and next_price > 0:
                return (next_price - current_price) / current_price
            else:
                return 0.0
        except:
            return 0.0
    
    def _get_price(self, date, ticker):
        """íŠ¹ì • ë‚ ì§œì˜ ì£¼ê°€ ê°€ì ¸ì˜¤ê¸°"""
        if isinstance(date, str):
            date = pd.to_datetime(date)
        
        # ìˆ˜ì •: ì»¬ëŸ¼ëª…ì„ ëŒ€ë¬¸ìë¡œ í†µì¼
        price_row = self.market_data[
            (pd.to_datetime(self.market_data['Date']) == date) & 
            (self.market_data['Ticker'] == ticker)
        ]
        
        if len(price_row) > 0:
            return price_row['Close'].iloc[0]  # ìˆ˜ì •: ëŒ€ë¬¸ìë¡œ í†µì¼
        else:
            return 0.0
    
    def _calculate_reward(self, action, market_return, state):
        """í–¥ìƒëœ ë³´ìƒ í•¨ìˆ˜"""
        base_reward = action * market_return * 10
        
        # ìƒíƒœ ì¸ë±ìŠ¤ ìˆ˜ì • (ê¸°ë³¸ í”¼ì²˜ ê°œìˆ˜ê°€ ë³€ìˆ˜ì´ë¯€ë¡œ)
        state_idx = len(self.feature_cols)
        transformer_pred = state[state_idx]      
        transformer_conf = state[state_idx + 1]  
        transformer_signal = state[state_idx + 2]
        
        # ê°ì • ì ìˆ˜
        google_positive = state[state_idx + 3]
        google_negative = state[state_idx + 4]
        reddit_positive = state[state_idx + 6]
        reddit_negative = state[state_idx + 7]
        
        # ë°©í–¥ì„± ì¼ì¹˜ ë³´ë„ˆìŠ¤
        direction_bonus = 0
        if transformer_signal > 0.5 and action > 0:
            direction_bonus = 0.1 * transformer_conf
        elif transformer_signal < 0.5 and action < 0:
            direction_bonus = 0.1 * transformer_conf
        
        # ê°ì •-í–‰ë™ ì¼ì¹˜ ë³´ë„ˆìŠ¤
        sentiment_bonus = 0
        google_sentiment = google_positive - google_negative
        if google_sentiment > 0.1 and action > 0:
            sentiment_bonus += 0.03
        elif google_sentiment < -0.1 and action < 0:
            sentiment_bonus += 0.03
        
        reddit_sentiment = reddit_positive - reddit_negative
        if reddit_sentiment > 0.1 and action > 0:
            sentiment_bonus += 0.02
        elif reddit_sentiment < -0.1 and action < 0:
            sentiment_bonus += 0.02
        
        # ìµœì¢… ë³´ìƒ ê³„ì‚°
        enhanced_reward = (
            base_reward * (1 + transformer_conf * 0.2) + 
            direction_bonus + 
            sentiment_bonus
        )
        
        return enhanced_reward

class EnhancedTD3Agent:
    def __init__(self, state_dim, action_dim, max_action):
        self.state_dim = state_dim
        self.action_dim = action_dim  # 8 (7ì¢…ëª© + holding_period)
        self.max_action = max_action

        self.actor = Actor(state_dim, action_dim, max_action)
        self.critic_1 = Critic(state_dim, action_dim)
        self.critic_2 = Critic(state_dim, action_dim)

        self.actor_target = Actor(state_dim, action_dim, max_action)
        self.critic_1_target = Critic(state_dim, action_dim)
        self.critic_2_target = Critic(state_dim, action_dim)

        self.actor_target.load_state_dict(self.actor.state_dict())
        self.critic_1_target.load_state_dict(self.critic_1.state_dict())
        self.critic_2_target.load_state_dict(self.critic_2.state_dict())

        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=3e-4)
        self.critic_1_optimizer = torch.optim.Adam(self.critic_1.parameters(), lr=3e-4)
        self.critic_2_optimizer = torch.optim.Adam(self.critic_2.parameters(), lr=3e-4)

        self.replay_buffer = ReplayBuffer(100000)
        self.tau = 0.005
        self.policy_noise = 0.2
        self.noise_clip = 0.5
        self.policy_freq = 2
        self.total_it = 0
    
    def select_action(self, state, noise=0.1):
        """í–‰ë™ ì„ íƒ"""
        state_tensor = torch.FloatTensor(state.reshape(1, -1))
        action = self.actor(state_tensor).cpu().data.numpy().flatten()
        
        if noise != 0:
            action = action + np.random.normal(0, noise, size=self.action_dim)
            action = action.clip(-self.max_action, self.max_action)
            
        return action
    
    def train(self, batch_size=256):
        """TD3 í›ˆë ¨"""
        if len(self.replay_buffer) < batch_size:
            return
        
        self.total_it += 1
        
        # ë°°ì¹˜ ìƒ˜í”Œë§
        state, action, next_state, reward, done = self.replay_buffer.sample(batch_size)
        
        with torch.no_grad():
            # íƒ€ê²Ÿ ì •ì±… ìŠ¤ë¬´ë”©
            noise = (torch.randn_like(action) * self.policy_noise).clamp(-self.noise_clip, self.noise_clip)
            next_action = (self.actor_target(next_state) + noise).clamp(-self.max_action, self.max_action)
            
            # íƒ€ê²Ÿ Q ê°’ ê³„ì‚°
            target_Q1 = self.critic_1_target(next_state, next_action)
            target_Q2 = self.critic_2_target(next_state, next_action)
            target_Q = torch.min(target_Q1, target_Q2)
            target_Q = reward + (1 - done) * 0.99 * target_Q
        
        # í˜„ì¬ Q ê°’
        current_Q1 = self.critic_1(state, action)
        current_Q2 = self.critic_2(state, action)
        
        critic_loss = nn.MSELoss()(current_Q1, target_Q) + nn.MSELoss()(current_Q2, target_Q)
        
        # í¬ë¦¬í‹± ì—…ë°ì´íŠ¸
        self.critic_1_optimizer.zero_grad()
        self.critic_2_optimizer.zero_grad()
        critic_loss.backward()
        self.critic_1_optimizer.step()
        self.critic_2_optimizer.step()
        
        # ì§€ì—°ëœ ì •ì±… ì—…ë°ì´íŠ¸
        if self.total_it % self.policy_freq == 0:
            # ì•¡í„° ì†ì‹¤
            actor_loss = -self.critic_1(state, self.actor(state)).mean()
            
            # ì•¡í„° ì—…ë°ì´íŠ¸
            self.actor_optimizer.zero_grad()
            actor_loss.backward()
            self.actor_optimizer.step()
            
            # ì†Œí”„íŠ¸ ì—…ë°ì´íŠ¸
            self.soft_update(self.actor, self.actor_target)
            self.soft_update(self.critic_1, self.critic_1_target)
            self.soft_update(self.critic_2, self.critic_2_target)
    
    def soft_update(self, source, target):
        """ì†Œí”„íŠ¸ ì—…ë°ì´íŠ¸"""
        for target_param, source_param in zip(target.parameters(), source.parameters()):
            target_param.data.copy_(target_param.data * (1.0 - self.tau) + source_param.data * self.tau)

class Actor(nn.Module):
    """ì•¡í„° ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, state_dim, action_dim, max_action):
        super(Actor, self).__init__()
        
        self.l1 = nn.Linear(state_dim, 400)
        self.l2 = nn.Linear(400, 300)
        self.l3 = nn.Linear(300, action_dim)
        
        self.max_action = max_action
        
    def forward(self, state):
        a = torch.relu(self.l1(state))
        a = torch.relu(self.l2(a))
        return self.max_action * torch.tanh(self.l3(a))

class Critic(nn.Module):
    """í¬ë¦¬í‹± ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, state_dim, action_dim):
        super(Critic, self).__init__()
        
        self.l1 = nn.Linear(state_dim + action_dim, 400)
        self.l2 = nn.Linear(400, 300)
        self.l3 = nn.Linear(300, 1)
        
    def forward(self, state, action):
        sa = torch.cat([state, action], 1)
        
        q1 = torch.relu(self.l1(sa))
        q1 = torch.relu(self.l2(q1))
        q1 = self.l3(q1)
        
        return q1

class ReplayBuffer:
    """ë¦¬í”Œë ˆì´ ë²„í¼"""
    
    def __init__(self, capacity):
        self.capacity = capacity
        self.buffer = []
        self.position = 0
    
    def add(self, state, action, next_state, reward, done):
        if len(self.buffer) < self.capacity:
            self.buffer.append(None)
        
        self.buffer[self.position] = (state, action, next_state, reward, done)
        self.position = (self.position + 1) % self.capacity
    
    def sample(self, batch_size):
        batch = np.random.choice(len(self.buffer), batch_size, replace=False)
        state, action, next_state, reward, done = zip(*[self.buffer[i] for i in batch])
        
        return (
            torch.FloatTensor(state),
            torch.FloatTensor(action),
            torch.FloatTensor(next_state),
            torch.FloatTensor(reward),
            torch.FloatTensor(done)
        )
    
    def __len__(self):
        return len(self.buffer)

class HierarchicalTradingSystem:
    """ê³„ì¸µì  ê±°ë˜ ì‹œìŠ¤í…œ í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, transformer_model_path, market_data, sentiment_data_paths):
        # í™˜ê²½ ì´ˆê¸°í™”
        self.env = HierarchicalTradingEnvironment(
            transformer_model_path, market_data, sentiment_data_paths
        )
        
        # RL ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        self.agent = EnhancedTD3Agent(
            state_dim=self.env.state_dim,
            action_dim=8,  # 8ê°œ ì¢…ëª©
            max_action=1.0  # ì •ê·œí™”ëœ í–‰ë™ ë²”ìœ„
        )
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_log = []
        
    def train_integrated_system(self, episodes=1000):
        tickers = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA', 'META', 'NVDA']

        try:
            for episode in range(episodes):
                total_reward = 0
                steps = 0
                train_dates = self.sample_training_period()

                if isinstance(train_dates, pd.Series):
                    train_dates = train_dates.tolist()
                elif hasattr(train_dates, 'tolist'):
                    train_dates = train_dates.tolist()

                if len(train_dates) < 2:
                    print(f"Episode {episode}: í›ˆë ¨ ë‚ ì§œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue

                for i in range(len(train_dates) - 1):
                    date = train_dates[i]
                    episode_rewards = []

                    for ticker_idx, ticker in enumerate(tickers):
                        try:
                            state = self.env.get_state(date, ticker)
                            action_vector = self.agent.select_action(state)

                            # ì¢…ëª©ë³„ í–‰ë™
                            pos_action = action_vector[ticker_idx]

                            # í™˜ê²½ ìŠ¤í… (ë³´ìœ ê¸°ê°„ í¬í•¨)
                            next_state, reward, done = self.env.step(action_vector, date, ticker)

                            self.agent.replay_buffer.add(
                                state, action_vector, next_state, reward, done
                            )

                            if len(self.agent.replay_buffer) > 1000:
                                self.agent.train()

                            total_reward += reward
                            episode_rewards.append(reward)
                            steps += 1

                        except Exception as e:
                            print(f"Episode {episode}, {ticker}, {date}: ì˜¤ë¥˜ ë°œìƒ - {e}")
                            continue

                    if len(episode_rewards) == 0:
                        break

                avg_reward = np.mean(episode_rewards) if episode_rewards else 0
                self.performance_log.append({
                    'episode': episode,
                    'total_reward': total_reward,
                    'avg_reward': avg_reward,
                    'steps': steps
                })

                if episode % 100 == 0:
                    print(f"Episode {episode}: Avg Reward = {avg_reward:.4f}, Total Reward = {total_reward:.4f}")

            print(f"âœ… í›ˆë ¨ ì™„ë£Œ: {episodes} ì—í”¼ì†Œë“œ")
        except Exception as e:
            print(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜: {e}")
            raise SystemExit(f"í›ˆë ¨ ì‹¤íŒ¨: {e}")
            
    def make_trading_decision(self, date, ticker):
        """ì‹¤ì œ ê±°ë˜ ê²°ì •"""
        
        try:
            # í˜„ì¬ ìƒíƒœ íšë“
            state = self.env.get_state(date, ticker)
            
            # RL ì—ì´ì „íŠ¸ í–‰ë™ ì„ íƒ (ë…¸ì´ì¦ˆ ì œê±°)
            action = self.agent.select_action(state, noise=0)
            
            # ì˜ì‚¬ê²°ì • í•´ì„
            decision = self.interpret_action(action[0], state)  # ì²« ë²ˆì§¸ í–‰ë™ë§Œ ì‚¬ìš©
            
            return decision
            
        except SystemExit:
            # ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹ í˜¸ ì¬ì „íŒŒ
            raise
        except Exception as e:
            print(f"âŒ ê±°ë˜ ê²°ì • ì˜¤ë¥˜ ({date}, {ticker}): {e}")
            print(f"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            raise SystemExit(f"ê±°ë˜ ê²°ì • ì‹¤íŒ¨: {e}")
    
    def interpret_action(self, action, state):
        """í–‰ë™ì„ ê±°ë˜ ê²°ì •ìœ¼ë¡œ í•´ì„"""
        
        # ìƒíƒœ ì¸ë±ìŠ¤ ìˆ˜ì • (ê¸°ë³¸ í”¼ì²˜ ê°œìˆ˜ê°€ ë³€ìˆ˜ì´ë¯€ë¡œ)
        state_idx = len(self.env.feature_cols)
        transformer_pred = state[state_idx]
        transformer_conf = state[state_idx + 1]
        transformer_signal = state[state_idx + 2]
        
        # ê°ì • ì ìˆ˜
        google_sentiment = state[state_idx + 3] - state[state_idx + 4]  # positive - negative
        reddit_sentiment = state[state_idx + 6] - state[state_idx + 7]  # positive - negative
        
        # í–‰ë™ ê°•ë„ ê³„ì‚°
        action_strength = abs(action)
        
        # ì˜ì‚¬ê²°ì • ë¡œì§
        if action_strength < 0.1:
            decision = "HOLD"
            confidence = "LOW"
        elif action > 0:
            decision = "BUY"
            confidence = "HIGH" if action_strength > 0.5 else "MEDIUM"
        else:
            decision = "SELL"
            confidence = "HIGH" if action_strength > 0.5 else "MEDIUM"
        
        return {
            'action': decision,
            'confidence': confidence,
            'quantity': action_strength,
            'reasoning': {
                'transformer_prediction': f"{transformer_pred:.2f}",
                'transformer_confidence': f"{transformer_conf:.2f}",
                'transformer_signal': 'UP' if transformer_signal > 0.5 else 'DOWN',
                'google_sentiment': f"{google_sentiment:.2f}",
                'reddit_sentiment': f"{reddit_sentiment:.2f}",
                'rl_action': f"{action:.2f}"
            }
        }
    
    def sample_training_period(self):
        """í›ˆë ¨ìš© ë‚ ì§œ ìƒ˜í”Œë§"""
        # ì‹¤ì œ ë°ì´í„° ê¸°ê°„ì—ì„œ ìƒ˜í”Œë§
        if len(self.env.market_data) > 0:
            available_dates = pd.to_datetime(self.env.market_data['Date']).unique()  # ìˆ˜ì •: ëŒ€ë¬¸ìë¡œ í†µì¼
            available_dates = pd.Series(available_dates).sort_values()
            
            # 30ì¼ ê¸°ê°„ ì„ íƒ
            if len(available_dates) >= 30:
                start_idx = np.random.randint(0, len(available_dates) - 30)
                selected_dates = available_dates.iloc[start_idx:start_idx + 30]
                return selected_dates.tolist()
            else:
                return available_dates.tolist()
        else:
            # ê¸°ë³¸ ê¸°ê°„
            start_date = pd.to_datetime('2020-01-01')
            date_range = pd.date_range(start_date, periods=30, freq='D')
            return date_range.tolist()

def load_market_data(file_path):
    """ì‹œì¥ ë°ì´í„° ë¡œë“œ"""
    try:
        data = pd.read_csv(file_path)
        
        # ì»¬ëŸ¼ëª… í†µì¼
        if 'date' in data.columns:
            data = data.rename(columns={'date': 'Date'})
        if 'tic' in data.columns:
            data = data.rename(columns={'tic': 'Ticker'})
        if 'ticker' in data.columns:
            data = data.rename(columns={'ticker': 'Ticker'})
            
        print(f"ì‹œì¥ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {file_path} - {len(data)} í–‰")
        print(f"ì»¬ëŸ¼: {data.columns.tolist()}")
        return data
    except Exception as e:
        print(f"ì‹œì¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ë°±í…ŒìŠ¤íŠ¸ ì½”ë“œ ì œê±°"""
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì • 
    transformer_model_path = '/Users/gamjawon/prometheus-11team/model/transformer_classifier_best.pt'
    market_data_path = "/Users/gamjawon/prometheus-11team/DATA/technical/M7_stock_momentum_data_fixed.csv"
    sentiment_data_paths = [
        "/Users/gamjawon/prometheus-11team/FinRL-Library/examples/data/M7_googlenews_2020_2022_sentiment_feature.csv",
        "/Users/gamjawon/prometheus-11team/FinRL-Library/examples/data/M7_reddits_2022_2025_sentiment_feature.csv"
    ]

    print("ğŸ“Š ë°ì´í„° ë° ëª¨ë¸ ë¡œë”© ì¤‘...")

    # ê¸°ë³¸ momentum ë°ì´í„° ë¡œë“œ
    market_data_raw = load_market_data(market_data_path)
    
    if market_data_raw.empty:
        print("âŒ ì‹œì¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ë‚ ì§œ í•„í„°ë§
    required_cols = ['Date', 'Ticker', 'Close', 'ROC_10', 'RSI_14', 'MACD']
    market_data_filtered = market_data_raw[required_cols].copy()
    market_data_filtered['Date'] = pd.to_datetime(market_data_filtered['Date'])
    market_data_filtered = market_data_filtered[market_data_filtered['Date'] >= '2020-01-01'].reset_index(drop=True)

    print(f"âœ… ê¸°ë³¸ ì‹œì¥ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(market_data_filtered)} rows")
    
    # Transformer ëª¨ë¸ ê²½ë¡œ í™•ì¸
    if not os.path.exists(transformer_model_path):
        raise FileNotFoundError(f"Transformer ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {transformer_model_path}")
    
    try:
        # í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì „ì²˜ë¦¬ í¬í•¨)
        trading_system = HierarchicalTradingSystem(
            transformer_model_path, market_data_filtered, sentiment_data_paths
        )
        
        print(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - ìƒíƒœ ì°¨ì›: {trading_system.env.state_dim}")
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (ì „ì²˜ë¦¬ëœ ë°ì´í„°ì—ì„œ)
        split_date = '2024-01-01'
        full_data = trading_system.env.market_data
        
        train_data = full_data[full_data['Date'] < split_date].copy().reset_index(drop=True)
        test_data = full_data[full_data['Date'] >= split_date].copy().reset_index(drop=True)
        
        print(f"âœ… í›ˆë ¨ ë°ì´í„°: {train_data['Date'].min().date()} ~ {train_data['Date'].max().date()} ({len(train_data)} rows)")
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_data['Date'].min().date()} ~ {test_data['Date'].max().date()} ({len(test_data)} rows)")
        
        # ì‹œìŠ¤í…œ í›ˆë ¨
        print("\nğŸš€ í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨ ì‹œì‘...")
        # í›ˆë ¨ì„ ìœ„í•´ market_dataë¥¼ train_dataë¡œ ì¼ì‹œ ë³€ê²½
        original_market_data = trading_system.env.market_data
        trading_system.env.market_data = train_data
        
        trading_system.train_integrated_system(episodes=500)
        
        # ì›ë³¸ ë°ì´í„°ë¡œ ë³µì›
        trading_system.env.market_data = original_market_data
        
        # ì‹¤ì œ ê±°ë˜ ê²°ì • í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š ê±°ë˜ ê²°ì • í…ŒìŠ¤íŠ¸...")
        
        # í…ŒìŠ¤íŠ¸í•  ë‚ ì§œ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ì„ íƒ)
        available_dates = pd.to_datetime(test_data['Date']).unique()
        available_dates = sorted(available_dates)
        test_date = available_dates[10] if len(available_dates) >= 10 else available_dates[0]
        
        test_tickers = ['AAPL', 'GOOGL', 'TSLA', 'MSFT', 'AMZN']
        
        for ticker in test_tickers:
            try:
                decision = trading_system.make_trading_decision(test_date, ticker)
                print(f"\n{ticker} ê±°ë˜ ê²°ì • ({test_date.strftime('%Y-%m-%d')}):")
                print(f"  ğŸ“ˆ í–‰ë™: {decision['action']}")
                print(f"  ğŸ¯ í™•ì‹ ë„: {decision['confidence']}")
                print(f"  ğŸ“Š ìˆ˜ëŸ‰: {decision['quantity']:.3f}")
                print(f"  ğŸ§  ê·¼ê±°:")
                for key, value in decision['reasoning'].items():
                    print(f"    - {key}: {value}")
                    
            except Exception as e:
                print(f"  âŒ {ticker} ê²°ì • ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ì„±ëŠ¥ ìš”ì•½
        if trading_system.performance_log:
            print("\nğŸ“ˆ í›ˆë ¨ ì„±ëŠ¥ ìš”ì•½:")
            recent_performance = trading_system.performance_log[-50:]  # ìµœê·¼ 50 ì—í”¼ì†Œë“œ
            avg_reward = np.mean([p['avg_reward'] for p in recent_performance])
            print(f"  í‰ê·  ë³´ìƒ (ìµœê·¼ 50 ì—í”¼ì†Œë“œ): {avg_reward:.4f}")
            print(f"  ì´ í›ˆë ¨ ì—í”¼ì†Œë“œ: {len(trading_system.performance_log)}")
        
        # ëª¨ë¸ ì €ì¥
        save_trained_model(trading_system, "trained_hierarchical_model.pth")
        
        print("\nâœ… ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

def save_trained_model(trading_system, save_path):
    """í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥"""
    try:
        model_state = {
            'actor_state_dict': trading_system.agent.actor.state_dict(),
            'critic_1_state_dict': trading_system.agent.critic_1.state_dict(),
            'critic_2_state_dict': trading_system.agent.critic_2.state_dict(),
            'state_dim': trading_system.env.state_dim,
            'action_dim': trading_system.agent.action_dim,
            'performance_log': trading_system.performance_log
        }
        
        torch.save(model_state, save_path)
        print(f"âœ… í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥: {save_path}")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")

def load_trained_model(load_path, transformer_model_path, market_data, sentiment_data_paths, weights_only=False):
    """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        trading_system = HierarchicalTradingSystem(
            transformer_model_path, market_data, sentiment_data_paths
        )
        
        # ì €ì¥ëœ ìƒíƒœ ë¡œë“œ
        checkpoint = torch.load(load_path, map_location='cpu', weights_only=weights_only)
        
        trading_system.agent.actor.load_state_dict(checkpoint['actor_state_dict'])
        trading_system.agent.critic_1.load_state_dict(checkpoint['critic_1_state_dict'])
        trading_system.agent.critic_2.load_state_dict(checkpoint['critic_2_state_dict'])
        
        if 'performance_log' in checkpoint:
            trading_system.performance_log = checkpoint['performance_log']
        
        print(f"âœ… í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ: {load_path}")
        return trading_system
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

if __name__ == "__main__":
    main()