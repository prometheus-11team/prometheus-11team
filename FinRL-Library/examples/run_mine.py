import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from finrl.meta.preprocessor.preprocessors import data_split
from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv
from finrl.agents.stablebaselines3.models import DRLAgent
import os
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs("results", exist_ok=True)
os.makedirs("logs", exist_ok=True)
os.makedirs("models", exist_ok=True)

# =============================================================================
# 1. Transformer ëª¨ë¸ ì •ì˜ (ë‘ ë²ˆì§¸ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´)
# =============================================================================

class TransformerClassifier(nn.Module):
    def __init__(self, input_dim, d_model=64, nhead=4, layers=2):
        super().__init__()
        self.input_dim = input_dim
        self.embed = nn.Linear(input_dim, d_model)
        enc = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)
        self.encoder = nn.TransformerEncoder(enc, layers)
        self.head = nn.Linear(d_model, 1)
    
    def forward(self, x):
        x = self.embed(x)
        x = self.encoder(x)
        return torch.sigmoid(self.head(x[:, -1]))  # (B,1)

# =============================================================================
# 2. í™•ì¥ëœ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤
# =============================================================================

class EnhancedDataProcessor:
    """í™•ì¥ëœ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, transformer_model_path=None):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.transformer_model = None
        self.scaler = StandardScaler()
        
        # Transformer ëª¨ë¸ ë¡œë“œ
        if transformer_model_path and os.path.exists(transformer_model_path):
            self.load_transformer_model(transformer_model_path)
    
    def load_transformer_model(self, model_path):
        """Transformer ëª¨ë¸ ë¡œë“œ"""
        try:
            self.transformer_model = TransformerClassifier(input_dim=17).to(self.device)
            state_dict = torch.load(model_path, map_location=self.device, weights_only=False)
            self.transformer_model.load_state_dict(state_dict)
            self.transformer_model.eval()
            print("âœ… Transformer ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Transformer ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.transformer_model = None
    
    def load_and_merge_data(self, stock_data_path, macro_data_path, financial_data_path, sentiment_data_paths):
        """ëª¨ë“  ë°ì´í„° ë¡œë“œ ë° ë³‘í•©"""
        
        # 1. ì£¼ì‹ ë°ì´í„° ë¡œë“œ
        df_stock = pd.read_csv(stock_data_path)
        df_stock["date"] = pd.to_datetime(df_stock["date"])
        df_stock = df_stock.rename(columns={"ticker": "tic"})
        df_stock = df_stock.sort_values(["date", "tic"]).reset_index(drop=True)
        
        # 2. ê±°ì‹œê²½ì œ ì§€í‘œ ë¡œë“œ
        if os.path.exists(macro_data_path):
            df_macro = pd.read_csv(macro_data_path)
            df_macro["date"] = pd.to_datetime(df_macro["date"])
            df_macro = df_macro.sort_values("date").reset_index(drop=True)
        else:
            print("ê±°ì‹œê²½ì œ ë°ì´í„°ê°€ ì—†ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •")
            df_macro = pd.DataFrame({
                'date': df_stock['date'].unique(),
                'federal_funds_rate': 0.0,
                'treasury_yield': 0.0,
                'cpi': 0.0,
                'unemployment_rate': 0.0
            })
        
        # 3. ì¬ë¬´ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        if os.path.exists(financial_data_path):
            df_financial = self._process_financial_data(financial_data_path, df_stock)
        else:
            print("ì¬ë¬´ ë°ì´í„°ê°€ ì—†ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •")
            df_financial = df_stock[['date', 'tic']].copy()
            for col in ['Operating Income', 'Net Income', 'EPS Diluted', 'Total Assets', 'Shareholders Equity']:
                df_financial[col] = 0.0
        
        # 4. ê°ì • ë¶„ì„ ë°ì´í„° ë¡œë“œ
        df_sentiment = self._load_sentiment_data(sentiment_data_paths, df_stock)
        
        # 5. ëª¨ë“  ë°ì´í„° ë³‘í•©
        df_merged = self._merge_all_data(df_stock, df_macro, df_financial, df_sentiment)
        
        # 6. Transformer ì˜ˆì¸¡ ì¶”ê°€
        df_merged = self._add_transformer_predictions(df_merged)
        
        return df_merged
    
    def _process_financial_data(self, financial_path, df_stock):
        """ì¬ë¬´ ë°ì´í„° ì „ì²˜ë¦¬"""
        try:
            financial_data = pd.read_csv(financial_path)
            
            # íšŒì‚¬ëª…-í‹°ì»¤ ë§¤í•‘
            company_to_ticker = {
                'Alphabet': 'GOOGL', 'Amazon': 'AMZN', 'Apple': 'AAPL',
                'Meta': 'META', 'Microsoft': 'MSFT', 'Nvidia': 'NVDA', 'Tesla': 'TSLA'
            }
            
            financial_data['tic'] = financial_data['Company'].map(company_to_ticker)
            financial_data['date'] = pd.to_datetime(financial_data['Release Date'])
            
            features = ['Operating Income', 'Net Income', 'EPS Diluted', 'Total Assets', 'Shareholders Equity']
            daily_index = pd.date_range(start=df_stock['date'].min(), end=df_stock['date'].max(), freq='D')
            
            daily_financial_list = []
            for ticker in financial_data['tic'].unique():
                if pd.isna(ticker):
                    continue
                df_t = financial_data.loc[financial_data['tic'] == ticker, ['date', 'tic'] + features].copy()
                df_t = df_t.set_index('date').sort_index()
                df_t = df_t[~df_t.index.duplicated(keep='last')]
                df_t = df_t.reindex(daily_index).ffill()
                df_t['tic'] = ticker
                df_t = df_t.reset_index().rename(columns={'index': 'date'})
                daily_financial_list.append(df_t)
            
            return pd.concat(daily_financial_list, ignore_index=True)
            
        except Exception as e:
            print(f"ì¬ë¬´ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            df_financial = df_stock[['date', 'tic']].copy()
            for col in ['Operating Income', 'Net Income', 'EPS Diluted', 'Total Assets', 'Shareholders Equity']:
                df_financial[col] = 0.0
            return df_financial
    
    def _load_sentiment_data(self, sentiment_data_paths, df_stock):
        """ê°ì • ë¶„ì„ ë°ì´í„° ë¡œë“œ"""
        sentiment_dfs = []
        
        for path in sentiment_data_paths:
            if os.path.exists(path):
                try:
                    df = pd.read_csv(path)
                    
                    # ë‚ ì§œ ì»¬ëŸ¼ ì •ë¦¬
                    if 'date' in df.columns:
                        df['date'] = pd.to_datetime(df['date'])
                    elif 'datadate' in df.columns:
                        df['date'] = pd.to_datetime(df['datadate'])
                    
                    # ê°ì • ì ìˆ˜ ì •ë¦¬
                    if 'sentiment_score' in df.columns:
                        df['positive'] = df['sentiment_score'].apply(lambda x: max(0, x))
                        df['negative'] = df['sentiment_score'].apply(lambda x: max(0, -x))
                        df['neutral'] = df['sentiment_score'].apply(lambda x: 1 - abs(x) if abs(x) <= 1 else 0)
                    elif not all(col in df.columns for col in ['positive', 'negative', 'neutral']):
                        df['positive'] = 0.5
                        df['negative'] = 0.3
                        df['neutral'] = 0.2
                    
                    # ì†ŒìŠ¤ êµ¬ë¶„
                    if 'googlenews' in path:
                        df['source'] = 'google_news'
                    elif 'reddit' in path:
                        df['source'] = 'reddit'
                    else:
                        df['source'] = 'unknown'
                    
                    sentiment_dfs.append(df)
                    print(f"ê°ì • ë°ì´í„° ë¡œë“œ: {path} - {len(df)} í–‰")
                    
                except Exception as e:
                    print(f"ê°ì • ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ {path}: {e}")
        
        if sentiment_dfs:
            combined_sentiment = pd.concat(sentiment_dfs, ignore_index=True)
            
            # ë‚ ì§œë³„, ì¢…ëª©ë³„ë¡œ ê°ì • ì ìˆ˜ ì§‘ê³„
            sentiment_agg = combined_sentiment.groupby(['date', 'tic', 'source']).agg({
                'positive': 'mean',
                'negative': 'mean',
                'neutral': 'mean'
            }).reset_index()
            
            # í”¼ë²—í•˜ì—¬ ì†ŒìŠ¤ë³„ ê°ì • ì ìˆ˜ ë¶„ë¦¬
            sentiment_pivot = sentiment_agg.pivot_table(
                index=['date', 'tic'], 
                columns='source', 
                values=['positive', 'negative', 'neutral'],
                fill_value=0.3
            )
            
            # ì»¬ëŸ¼ëª… í‰íƒ„í™”
            sentiment_pivot.columns = ['_'.join(col).strip() for col in sentiment_pivot.columns]
            sentiment_pivot = sentiment_pivot.reset_index()
            
            return sentiment_pivot
        else:
            # ê¸°ë³¸ ê°ì • ë°ì´í„° ìƒì„±
            unique_combinations = df_stock[['date', 'tic']].drop_duplicates()
            sentiment_cols = [
                'positive_google_news', 'negative_google_news', 'neutral_google_news',
                'positive_reddit', 'negative_reddit', 'neutral_reddit'
            ]
            for col in sentiment_cols:
                unique_combinations[col] = 0.3
            
            return unique_combinations
    
    def _merge_all_data(self, df_stock, df_macro, df_financial, df_sentiment):
        """ëª¨ë“  ë°ì´í„° ë³‘í•©"""
        # ê±°ì‹œê²½ì œ ì§€í‘œ ë³‘í•©
        df_merged = pd.merge_asof(
            df_stock.sort_values('date'), 
            df_macro.sort_values('date'),
            on='date',
            direction='backward'
        )
        
        # ì¬ë¬´ ë°ì´í„° ë³‘í•©
        df_merged = pd.merge(df_merged, df_financial, on=['date', 'tic'], how='left')
        
        # ê°ì • ë°ì´í„° ë³‘í•©
        df_merged = pd.merge(df_merged, df_sentiment, on=['date', 'tic'], how='left')
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        macro_cols = [col for col in df_macro.columns if col != 'date']
        if macro_cols:
            df_merged[macro_cols] = df_merged[macro_cols].fillna(method='ffill').fillna(method='bfill')
        
        financial_cols = ['Operating Income', 'Net Income', 'EPS Diluted', 'Total Assets', 'Shareholders Equity']
        for col in financial_cols:
            if col in df_merged.columns:
                df_merged[col] = df_merged[col].fillna(0)
        
        sentiment_cols = [col for col in df_merged.columns if any(x in col for x in ['positive', 'negative', 'neutral'])]
        for col in sentiment_cols:
            df_merged[col] = df_merged[col].fillna(0.3)
        
        return df_merged
    
    def _add_transformer_predictions(self, df_merged):
        """Transformer ì˜ˆì¸¡ ì¶”ê°€"""
        if self.transformer_model is None:
            # Transformerê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€
            df_merged['transformer_prediction'] = 0.5
            df_merged['transformer_confidence'] = 0.0
            df_merged['transformer_signal'] = 0
            return df_merged
        
        # ê¸°ìˆ ì§€í‘œ ì»¬ëŸ¼ ì •ì˜
        tech_indicators = ['open', 'high', 'low', 'close', 'volume']
        
        # ê¸°ì¡´ ê¸°ìˆ ì§€í‘œ ì°¾ê¸°
        available_indicators = [col for col in df_merged.columns 
                              if any(indicator in col.lower() for indicator in 
                                   ['rsi', 'macd', 'ema', 'sma', 'bb', 'roc', 'atr', 'adx', 'cci', 'willr', 'momentum', 'stoch'])]
        
        feature_cols = tech_indicators + available_indicators
        feature_cols = [col for col in feature_cols if col in df_merged.columns]
        
        if len(feature_cols) < 17:
            # ë¶€ì¡±í•œ í”¼ì²˜ëŠ” 0ìœ¼ë¡œ íŒ¨ë”©
            for i in range(17 - len(feature_cols)):
                df_merged[f'padding_{i}'] = 0.0
                feature_cols.append(f'padding_{i}')
        
        transformer_predictions = []
        transformer_confidences = []
        transformer_signals = []
        
        for idx, row in df_merged.iterrows():
            try:
                # 17ê°œ í”¼ì²˜ ì¶”ì¶œ
                features = row[feature_cols[:17]].values.astype(float)
                features = np.nan_to_num(features, nan=0.0)
                
                # ì •ê·œí™”
                features = np.clip(features, -100, 100)
                
                # Transformer ì˜ˆì¸¡
                input_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
                
                with torch.no_grad():
                    prediction = self.transformer_model(input_tensor).cpu().numpy().flatten()[0]
                    confidence = abs(prediction - 0.5) * 2
                    signal = 1 if prediction > 0.5 else 0
                
                transformer_predictions.append(float(prediction))
                transformer_confidences.append(float(confidence))
                transformer_signals.append(signal)
                
            except Exception as e:
                transformer_predictions.append(0.5)
                transformer_confidences.append(0.0)
                transformer_signals.append(0)
        
        df_merged['transformer_prediction'] = transformer_predictions
        df_merged['transformer_confidence'] = transformer_confidences
        df_merged['transformer_signal'] = transformer_signals
        
        print(f"âœ… Transformer ì˜ˆì¸¡ {len(transformer_predictions)}ê°œ ì¶”ê°€ ì™„ë£Œ")
        df_merged = self._enhance_signals(df_merged)
        return df_merged
    
    def _enhance_signals(self, df):
        """ì…ë ¥ ì‹ í˜¸ë“¤ì„ ì¦í­í•˜ì—¬ ë” ê·¹ë‹¨ì ìœ¼ë¡œ ë§Œë“¤ê¸°"""
        
        # 1. Transformer ì˜ˆì¸¡ ì‹ í˜¸ ì¦í­
        if 'transformer_prediction' in df.columns:
            df['transformer_prediction'] = df['transformer_prediction'].apply(
                lambda x: 0.5 + (x - 0.5) * 2.5 if not pd.isna(x) else 0.5
            )
            df['transformer_prediction'] = df['transformer_prediction'].clip(0.1, 0.9)
        
        # 2. ê°ì • ë¶„ì„ ì‹ í˜¸ ì¦í­
        sentiment_cols = [col for col in df.columns if 'positive' in col or 'negative' in col]
        for col in sentiment_cols:
            if col in df.columns:
                # ì¤‘ë¦½ê°’(0.3)ì—ì„œ ë²—ì–´ë‚œ ì •ë„ë¥¼ 2ë°°ë¡œ ì¦í­
                df[col] = df[col].apply(
                    lambda x: 0.3 + (x - 0.3) * 2.0 if not pd.isna(x) else 0.3
                )
                df[col] = df[col].clip(0.1, 0.8)
        
        # 3. ê¸°ìˆ ì§€í‘œ ì •ê·œí™” (RSI, MACD ë“±)
        tech_cols = ['RSI_14', 'MACD', 'ROC_10']
        for col in tech_cols:
            if col in df.columns:
                # í‘œì¤€í™” í›„ ê·¹ë‹¨ê°’ ê°•ì¡°
                mean_val = df[col].mean()
                std_val = df[col].std()
                if std_val > 0:
                    df[col] = (df[col] - mean_val) / std_val
                    df[col] = df[col] * 1.5  # ì‹ í˜¸ ì¦í­
                    df[col] = df[col].clip(-3, 3)  # ê·¹ë‹¨ê°’ ì œí•œ
        
        print("âœ… ì…ë ¥ ì‹ í˜¸ ì¦í­ ì™„ë£Œ")
        return df

# =============================================================================
# 3. ë©”ì¸ ì‹¤í–‰ ì½”ë“œ (ì²« ë²ˆì§¸ ì½”ë“œ êµ¬ì¡° ìœ ì§€)
# =============================================================================

def main():
    print("ğŸ“Š í™•ì¥ëœ FinRL ì‹œìŠ¤í…œ ì‹œì‘...")
    
    # =============================================================================
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    # =============================================================================
    
    # ê¸°ë³¸ ë°ì´í„° ê²½ë¡œ
    stock_data_path = "/Users/gamjawon/prometheus-11team/FinRL-Library/examples/data/M7_stock_data_with_indicators.csv"
    macro_data_path = "/Users/gamjawon/prometheus-11team/DATA/technical/macro_indicators_2020_2025-03.csv"
    financial_data_path = "/Users/gamjawon/prometheus-11team/FinRL-Library/examples/data/M7_financial_data_2020_2025.csv"
    
    # ê°ì • ë¶„ì„ ë°ì´í„° ê²½ë¡œ
    sentiment_data_paths = [
        "/Users/gamjawon/prometheus-11team/FinRL-Library/examples/data/M7_googlenews_2020_2022_sentiment_feature.csv",
        "/Users/gamjawon/prometheus-11team/FinRL-Library/examples/data/M7_reddits_2022_2025_sentiment_feature.csv"
    ]
    
    # Transformer ëª¨ë¸ ê²½ë¡œ
    transformer_model_path = "/Users/gamjawon/prometheus-11team/model/transformer_classifier_best.pt"
    
    # =============================================================================
    # í™•ì¥ëœ ë°ì´í„° ì „ì²˜ë¦¬
    # =============================================================================
    
    print("ğŸ”„ í™•ì¥ëœ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
    
    # ë°ì´í„° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    data_processor = EnhancedDataProcessor(transformer_model_path)
    
    # ëª¨ë“  ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
    df = data_processor.load_and_merge_data(
        stock_data_path, macro_data_path, financial_data_path, sentiment_data_paths
    )
    
    print(f"âœ… í™•ì¥ëœ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! ì´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
    print(f"ë°ì´í„° ê¸°ê°„: {df['date'].min()} ~ {df['date'].max()}")
    print(f"ìƒˆë¡œ ì¶”ê°€ëœ í”¼ì²˜ë“¤:")
    
    # ìƒˆë¡œ ì¶”ê°€ëœ í”¼ì²˜ë“¤ í™•ì¸
    new_features = [col for col in df.columns if any(x in col for x in 
                   ['transformer', 'positive', 'negative', 'neutral', 'Operating', 'Net Income', 'EPS', 'Assets', 'Equity'])]
    for feature in new_features:
        print(f"  - {feature}")
    
    # =============================================================================
    # ê¸°ìˆ ì§€í‘œ ë° ìƒˆ ì§€í‘œ ì •ì˜ (ì²« ë²ˆì§¸ ì½”ë“œ ë°©ì‹ ìœ ì§€)
    # =============================================================================
    
    # ê¸°ë³¸ ì£¼ê°€ ë°ì´í„° ì»¬ëŸ¼
    basic_cols = ["date", "tic", "open", "high", "low", "close", "volume"]
    
    # ê¸°ì¡´ ê¸°ìˆ ì§€í‘œ (ì •í™•í•œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •)
    tech_indicators = ['SMA_50', 'SMA_200', 'RSI_14', 'ROC_10', 'MACD', 'MACD_Signal']
    # ì‹¤ì œ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ í›„ í•„í„°ë§
    tech_indicators = [col for col in tech_indicators if col in df.columns]
    
    # ê±°ì‹œê²½ì œ ì§€í‘œ (ì •í™•í•œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •)
    macro_indicators = [
        'Federal Funds Rate', 
        '10Y Treasury Yield', 
        'CPI', 
        'Core CPI', 
        'PCE Price Index', 
        'Retail Sales', 
        'Unemployment Rate', 
        'Non-Farm Payrolls', 
        'M2 Money Stock'
    ]
    # ì‹¤ì œ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ í›„ í•„í„°ë§
    macro_indicators = [col for col in macro_indicators if col in df.columns]
    
    # Transformer ì§€í‘œ
    transformer_indicators = ['transformer_prediction', 'transformer_confidence', 'transformer_signal']
    
    # ê°ì • ë¶„ì„ ì§€í‘œ
    sentiment_indicators = [col for col in df.columns if any(x in col for x in ['positive', 'negative', 'neutral'])]
    
    # ëª¨ë“  ì§€í‘œ í†µí•© (ì¬ë¬´ì§€í‘œ ì œì™¸)
    ALL_INDICATORS = tech_indicators + macro_indicators + transformer_indicators + sentiment_indicators
    
    print(f"\nğŸ“ˆ ì‚¬ìš©í•  ì§€í‘œë“¤:")
    print(f"ê¸°ìˆ ì§€í‘œ ({len(tech_indicators)}ê°œ): {tech_indicators}")
    print(f"ê±°ì‹œì§€í‘œ ({len(macro_indicators)}ê°œ): {macro_indicators}")
    print(f"Transformer ì§€í‘œ ({len(transformer_indicators)}ê°œ): {transformer_indicators}")
    print(f"ê°ì •ì§€í‘œ ({len(sentiment_indicators)}ê°œ): {sentiment_indicators}")
    print(f"ì´ ì§€í‘œ ìˆ˜: {len(ALL_INDICATORS)}ê°œ")

    # =============================================================================
    # ë°ì´í„° ë¶„í•  (ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼)
    # =============================================================================
    
    train_df = data_split(df, start="2020-01-01", end="2023-12-31")
    test_df = data_split(df, start="2024-01-01", end="2025-04-30")
    
    print(f"\nğŸ“Š ë°ì´í„° ë¶„í• :")
    print(f"í›ˆë ¨ ë°ì´í„°: {train_df['date'].min()} ~ {train_df['date'].max()} ({len(train_df)} rows)")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_df['date'].min()} ~ {test_df['date'].max()} ({len(test_df)} rows)")
    
    # =============================================================================
    # ë°ì´í„° ì „ì²˜ë¦¬ (ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼)
    # =============================================================================
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    train_df = train_df.fillna(method="ffill").fillna(method="bfill")
    test_df = test_df.fillna(method="ffill").fillna(method="bfill")
    
    # ê²°ì¸¡ì¹˜ ì œê±°
    train_df = train_df.dropna(subset=ALL_INDICATORS)
    test_df = test_df.dropna(subset=ALL_INDICATORS)
    
    # ì¸ë±ìŠ¤ ì¬ì„¤ì •
    train_df.reset_index(drop=True, inplace=True)
    test_df.reset_index(drop=True, inplace=True)
    
    train_df.index = train_df["date"].factorize()[0]
    test_df.index = test_df["date"].factorize()[0]
    
    print(f"\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ:")
    print(f"í›ˆë ¨ ë°ì´í„°: {len(train_df)} rows")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)} rows")
    
    # =============================================================================
    # í™˜ê²½ ì„¤ì • (í™•ì¥ëœ ìƒíƒœ ê³µê°„)
    # =============================================================================
    
    stock_dim = len(train_df["tic"].unique())
    state_space = 1 + 2 * stock_dim + len(ALL_INDICATORS) * stock_dim  # í™•ì¥ëœ ìƒíƒœ ê³µê°„
    
    env_kwargs = {
        "hmax": 800,
        "initial_amount": 1_000_000,
        "buy_cost_pct": [0.0005] * stock_dim,
        "sell_cost_pct": [0.001] * stock_dim,
        "state_space": state_space,
        "stock_dim": stock_dim,
        "tech_indicator_list": ALL_INDICATORS,  # í™•ì¥ëœ ì§€í‘œ ë¦¬ìŠ¤íŠ¸
        "action_space": stock_dim,
        "reward_scaling": 2e-1,
        "num_stock_shares": [0] * stock_dim,
        "turbulence_threshold": None,
        "day": 0
    }
    
    print(f"\nğŸ¯ í™•ì¥ëœ í™˜ê²½ ì„¤ì •:")
    print(f"ì£¼ì‹ ì¢…ëª© ìˆ˜: {stock_dim}")
    print(f"í™•ì¥ëœ ìƒíƒœ ê³µê°„ í¬ê¸°: {state_space}")
    print(f"ì „ì²´ ì§€í‘œ ìˆ˜: {len(ALL_INDICATORS)}")
    print(f"ìƒíƒœ ê³µê°„ êµ¬ì„±:")
    print(f"  - ê¸°ë³¸ ì •ë³´: 1 (í˜„ê¸ˆ)")
    print(f"  - ì£¼ì‹ ë³´ìœ ëŸ‰: {stock_dim}")
    print(f"  - ì£¼ì‹ ê°€ê²©: {stock_dim}")
    print(f"  - ê¸°ìˆ /ê±°ì‹œ/ì¬ë¬´/ê°ì •/Transformer ì§€í‘œ: {len(ALL_INDICATORS)} Ã— {stock_dim}")
    
    # =============================================================================
    # ëª¨ë¸ í•™ìŠµ (ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼í•˜ì§€ë§Œ í™•ì¥ëœ ì…ë ¥)
    # =============================================================================
    
    print(f"\nğŸš€ í™•ì¥ëœ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    
    env_train = StockTradingEnv(df=train_df, **env_kwargs)
    agent = DRLAgent(env=env_train)
    
    # TD3 ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
    model = agent.get_model("td3")
    trained_model = agent.train_model(
        model=model,
        tb_log_name="td3_with_enhanced_features",
        total_timesteps=150000
    )
    
    
    print("âœ… í™•ì¥ëœ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    
    # ëª¨ë¸ ì €ì¥
    model_save_path = os.path.join("models", "td3_enhanced_model(4)")
    trained_model.save(model_save_path)
    print(f"\nğŸ’¾ í™•ì¥ëœ ëª¨ë¸ì´ '{model_save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # =============================================================================
    # ë°±í…ŒìŠ¤íŒ… (ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼)
    # =============================================================================
    
    print(f"\nğŸ“Š í™•ì¥ëœ ëª¨ë¸ ë°±í…ŒìŠ¤íŒ… ì‹œì‘...")
    
    env_test = StockTradingEnv(df=test_df, **env_kwargs)
    df_account_value, df_actions = agent.DRL_prediction(model=trained_model, environment=env_test)
    
    print("âœ… ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ!")
    
    # =============================================================================
    # ì„±ëŠ¥ ë¶„ì„ (ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼)
    # =============================================================================
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ë“¤ (ì²« ë²ˆì§¸ ì½”ë“œì—ì„œ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜´)
    def calculate_total_return(df):
        start_value = df["account_value"].iloc[0]
        end_value = df["account_value"].iloc[-1]
        total_return = (end_value - start_value) / start_value
        return total_return
    
    def calculate_cagr(df):
        start_value = df["account_value"].iloc[0]
        end_value = df["account_value"].iloc[-1]
        n_days = (df["date"].iloc[-1] - df["date"].iloc[0]).days
        n_years = n_days / 365.25
        if n_years > 0:
            cagr = (end_value / start_value) ** (1 / n_years) - 1
        else:
            cagr = 0
        return cagr
    
    def calculate_mdd(df):
        cumulative = df["account_value"].cummax()
        drawdown = df["account_value"] / cumulative - 1
        mdd = drawdown.min()
        return mdd
    
    def calculate_sharpe_ratio(df, risk_free_rate=0.02):
        returns = df["account_value"].pct_change().dropna()
        excess_returns = returns - risk_free_rate/252
        if excess_returns.std() != 0:
            sharpe = excess_returns.mean() / excess_returns.std() * np.sqrt(252)
        else:
            sharpe = 0
        return sharpe
    
    def calculate_volatility(df):
        returns = df["account_value"].pct_change().dropna()
        volatility = returns.std() * np.sqrt(252)
        return volatility
    
    def calculate_benchmark_return(df_test, benchmark_tickers=["AAPL", "GOOGL", "MSFT"]):
        benchmark_returns = []
        
        for ticker in benchmark_tickers:
            df_ticker = df_test[df_test["tic"] == ticker].copy()
            if len(df_ticker) > 0:
                df_ticker = df_ticker.sort_values("date")
                buy_price = df_ticker.iloc[0]["close"]
                sell_price = df_ticker.iloc[-1]["close"]
                return_rate = (sell_price - buy_price) / buy_price
                benchmark_returns.append(return_rate)
        
        if benchmark_returns:
            avg_benchmark_return = np.mean(benchmark_returns)
        else:
            avg_benchmark_return = 0
            
        return avg_benchmark_return, benchmark_returns
    
    # ì„±ê³¼ ë¶„ì„
    print(f"\n" + "="*60)
    print(f"ğŸ“Š í™•ì¥ëœ ëª¨ë¸ ì„±ê³¼ ë¶„ì„ ê²°ê³¼")
    print(f"="*60)
    
    # DRL ëª¨ë¸ ì„±ê³¼
    total_return = calculate_total_return(df_account_value)
    cagr = calculate_cagr(df_account_value)
    mdd = calculate_mdd(df_account_value)
    sharpe = calculate_sharpe_ratio(df_account_value)
    volatility = calculate_volatility(df_account_value)
    
    # ë²¤ì¹˜ë§ˆí¬ ì„±ê³¼
    benchmark_return, individual_returns = calculate_benchmark_return(test_df)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ¤– í™•ì¥ëœ TD3 ëª¨ë¸ ì„±ê³¼:")
    print(f"   ğŸ’° ì´ ìˆ˜ìµë¥ : {total_return:.2%}")
    print(f"   ğŸ“ˆ ì—°ë³µë¦¬ ìˆ˜ìµë¥  (CAGR): {cagr:.2%}")
    print(f"   ğŸ“‰ ìµœëŒ€ ë‚™í­ (MDD): {mdd:.2%}")
    print(f"   âš¡ ìƒ¤í”„ ë¹„ìœ¨: {sharpe:.2f}")
    print(f"   ğŸ“Š ë³€ë™ì„±: {volatility:.2%}")
    
    print(f"\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ì„±ê³¼:")
    print(f"   ğŸ† í‰ê·  Buy & Hold ìˆ˜ìµë¥ : {benchmark_return:.2%}")
    for i, ticker in enumerate(["AAPL", "GOOGL", "MSFT"]):
        if i < len(individual_returns):
            print(f"   ğŸ“ˆ {ticker} Buy & Hold: {individual_returns[i]:.2%}")
    
    print(f"\nğŸ¯ ìƒëŒ€ ì„±ê³¼:")
    outperformance = total_return - benchmark_return
    print(f"   ğŸš€ ì´ˆê³¼ ìˆ˜ìµë¥ : {outperformance:.2%}")
    print(f"   ğŸ“ˆ ì„±ê³¼: {'ìŠ¹ë¦¬! ğŸ‰' if outperformance > 0 else 'ì•„ì‰½... ğŸ“‰'}")
    
    # ìµœì¢… í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜
    final_value = df_account_value["account_value"].iloc[-1]
    initial_value = df_account_value["account_value"].iloc[0]
    profit = final_value - initial_value
    
    print(f"\nğŸ’ ìµœì¢… ê²°ê³¼:")
    print(f"   ğŸ¦ ì´ˆê¸° ìê¸ˆ: {initial_value:,.0f}ì›")
    print(f"   ğŸ’° ìµœì¢… ìê¸ˆ: {final_value:,.0f}ì›")
    print(f"   ğŸ’µ ì ˆëŒ€ ìˆ˜ìµ: {profit:,.0f}ì›")
    
    # =============================================================================
    # í™•ì¥ëœ íŠ¹ì„± ë¶„ì„
    # =============================================================================
    
    print(f"\n" + "="*60)
    print(f"ğŸ” í™•ì¥ëœ íŠ¹ì„± ê¸°ì—¬ë„ ë¶„ì„")
    print(f"="*60)
    
    # ê° íŠ¹ì„± ê·¸ë£¹ë³„ í†µê³„
    print(f"ğŸ“Š ì‚¬ìš©ëœ íŠ¹ì„± ê·¸ë£¹:")
    print(f"   ğŸ”§ ê¸°ìˆ ì§€í‘œ: {len(tech_indicators)}ê°œ")
    print(f"   ğŸŒ ê±°ì‹œì§€í‘œ: {len(macro_indicators)}ê°œ") 
    print(f"   ğŸ¤– Transformer: {len(transformer_indicators)}ê°œ")
    print(f"   ğŸ˜Š ê°ì •ì§€í‘œ: {len(sentiment_indicators)}ê°œ")
    
    # Transformer ì˜ˆì¸¡ ì •í™•ë„ ë¶„ì„ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ)
    if 'transformer_prediction' in test_df.columns:
        transformer_preds = test_df['transformer_prediction'].values
        print(f"\nğŸ¤– Transformer ì˜ˆì¸¡ ë¶„ì„:")
        print(f"   í‰ê·  ì˜ˆì¸¡ê°’: {np.mean(transformer_preds):.3f}")
        print(f"   ì˜ˆì¸¡ ë¶„ì‚°: {np.var(transformer_preds):.3f}")
        print(f"   ê°•ì„¸ ì˜ˆì¸¡ ë¹„ìœ¨: {np.mean(transformer_preds > 0.5):.1%}")
    
    # ê°ì • ì§€í‘œ ë¶„ì„
    sentiment_cols = [col for col in test_df.columns if 'positive' in col or 'negative' in col]
    if sentiment_cols:
        print(f"\nğŸ˜Š ê°ì • ë¶„ì„:")
        for col in sentiment_cols[:4]:  # ì²˜ìŒ 4ê°œë§Œ ì¶œë ¥
            if col in test_df.columns:
                avg_sentiment = test_df[col].mean()
                print(f"   {col}: {avg_sentiment:.3f}")
    
    # =============================================================================
    # ì‹œê°í™” (í™•ì¥ëœ ë²„ì „)
    # =============================================================================
    
    plt.figure(figsize=(20, 12))
    
    # 1. í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™”
    plt.subplot(3, 3, 1)
    plt.plot(df_account_value["date"], df_account_value["account_value"], 'b-', linewidth=2, label='Enhanced DRL Portfolio')
    plt.axhline(y=initial_value, color='gray', linestyle='--', alpha=0.7, label='Initial Value')
    plt.title('ğŸ“ˆ Enhanced Portfolio Value Over Time')
    plt.xlabel('Date')
    plt.ylabel('Portfolio Value (ì›)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    # 2. ìˆ˜ìµë¥  ë³€í™”
    plt.subplot(3, 3, 2)
    returns = df_account_value["account_value"].pct_change().dropna()
    cumulative_returns = (1 + returns).cumprod() - 1
    plt.plot(df_account_value["date"][1:], cumulative_returns * 100, 'g-', linewidth=2)
    plt.title('ğŸ“Š Cumulative Returns (%)')
    plt.xlabel('Date')
    plt.ylabel('Cumulative Return (%)')
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    # 3. ë“œë¡œìš°ë‹¤ìš´
    plt.subplot(3, 3, 3)
    cumulative = df_account_value["account_value"].cummax()
    drawdown = (df_account_value["account_value"] / cumulative - 1) * 100
    plt.fill_between(df_account_value["date"], drawdown, 0, color='red', alpha=0.3)
    plt.plot(df_account_value["date"], drawdown, 'r-', linewidth=1)
    plt.title('ğŸ“‰ Drawdown (%)')
    plt.xlabel('Date')
    plt.ylabel('Drawdown (%)')
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    # 4. ê±°ë˜ í™œë™
    plt.subplot(3, 3, 4)
    if len(df_actions) > 0:
        action_cols = [col for col in df_actions.columns if col != 'date']
        daily_trades = df_actions[action_cols].abs().sum(axis=1)
        plt.plot(range(len(daily_trades)), daily_trades, 'purple', linewidth=1)
        plt.title('ğŸ”„ Daily Trading Activity')
        plt.xlabel('Time steps')
        plt.ylabel('Total Trades')
        plt.grid(True, alpha=0.3)
    
    # 5. Transformer ì˜ˆì¸¡ ë¶„í¬
    plt.subplot(3, 3, 5)
    if 'transformer_prediction' in test_df.columns:
        plt.hist(test_df['transformer_prediction'], bins=30, alpha=0.7, color='orange')
        plt.axvline(x=0.5, color='red', linestyle='--', label='Neutral')
        plt.title('ğŸ¤– Transformer Predictions Distribution')
        plt.xlabel('Prediction Value')
        plt.ylabel('Frequency')
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    # 6. ê°ì • ì§€í‘œ ì‹œê³„ì—´
    plt.subplot(3, 3, 6)
    if 'positive_google_news' in test_df.columns and 'negative_google_news' in test_df.columns:
        # ë‚ ì§œë³„ í‰ê·  ê°ì • ê³„ì‚°
        sentiment_by_date = test_df.groupby('date').agg({
            'positive_google_news': 'mean',
            'negative_google_news': 'mean'
        }).reset_index()
        
        plt.plot(sentiment_by_date['date'], sentiment_by_date['positive_google_news'], 
                'g-', label='Positive', alpha=0.7)
        plt.plot(sentiment_by_date['date'], sentiment_by_date['negative_google_news'], 
                'r-', label='Negative', alpha=0.7)
        plt.title('ğŸ˜Š Google News Sentiment Over Time')
        plt.xlabel('Date')
        plt.ylabel('Sentiment Score')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
    
    # 7. íŠ¹ì„± ì¤‘ìš”ë„ (ê·¼ì‚¬ì¹˜)
    plt.subplot(3, 3, 7)
    feature_groups = ['Tech', 'Macro', 'Transformer', 'Sentiment']
    feature_counts = [len(tech_indicators), len(macro_indicators), 
                     len(transformer_indicators), 
                     len(sentiment_indicators)]
    
    print(f"feature_groups ê¸¸ì´: {len(feature_groups)}")
    print(f"feature_counts ê¸¸ì´: {len(feature_counts)}")
    print(f"feature_groups: {feature_groups}")
    print(f"feature_counts: {feature_counts}")
    
    colors = ['blue', 'green', 'orange', 'red', 'purple']
    plt.bar(feature_groups, feature_counts, color=colors, alpha=0.7)
    plt.title('ğŸ“Š Feature Groups Distribution')
    plt.xlabel('Feature Groups')
    plt.ylabel('Number of Features')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    # 8. ìˆ˜ìµë¥  ë¶„í¬
    plt.subplot(3, 3, 8)
    daily_returns = df_account_value["account_value"].pct_change().dropna() * 100
    plt.hist(daily_returns, bins=50, alpha=0.7, color='skyblue')
    plt.axvline(x=daily_returns.mean(), color='red', linestyle='--', 
                label=f'Mean: {daily_returns.mean():.2f}%')
    plt.title('ğŸ“ˆ Daily Returns Distribution')
    plt.xlabel('Daily Return (%)')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 9. ì„±ê³¼ ìš”ì•½
    plt.subplot(3, 3, 9)
    plt.axis('off')
    summary_text = f"""
    ğŸ“Š Enhanced Model Summary
    
    ğŸ¯ Total Return: {total_return:.1%}
    ğŸ“ˆ CAGR: {cagr:.1%}
    ğŸ“‰ Max Drawdown: {mdd:.1%}
    âš¡ Sharpe Ratio: {sharpe:.2f}
    ğŸ“Š Volatility: {volatility:.1%}
    
    ğŸ†š vs Benchmark: {outperformance:.1%}
    
    ğŸ”§ Total Features: {len(ALL_INDICATORS)}
    ğŸ¤– With Transformer: âœ“
    ğŸ˜Š With Sentiment: âœ“
    ğŸ’¼ With Financials: âœ“
    """
    plt.text(0.1, 0.5, summary_text, fontsize=10, verticalalignment='center',
             bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
    
    plt.tight_layout()
    plt.savefig("results/enhanced_comprehensive_analysis.png", dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\nğŸ’¾ í™•ì¥ëœ ë¶„ì„ ê²°ê³¼ê°€ 'results/enhanced_comprehensive_analysis.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # =============================================================================
    # ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥
    # =============================================================================
    
    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ì €ì¥
    result_summary = pd.DataFrame({
        'metric': ['Total Return', 'CAGR', 'Max Drawdown', 'Sharpe Ratio', 'Volatility', 'Outperformance'],
        'value': [total_return, cagr, mdd, sharpe, volatility, outperformance]
    })
    
    result_summary.to_csv("results/enhanced_performance_summary.csv", index=False)
    
    # í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì €ì¥
    df_account_value.to_csv("results/enhanced_portfolio_values.csv", index=False)
    
    # ê±°ë˜ ê¸°ë¡ ì €ì¥
    if len(df_actions) > 0:
        df_actions.to_csv("results/enhanced_trading_actions.csv", index=False)
    
    print(f"\nğŸ’¾ ì¶”ê°€ ê²°ê³¼ íŒŒì¼ë“¤ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
    print(f"   - results/enhanced_performance_summary.csv")
    print(f"   - results/enhanced_portfolio_values.csv")
    print(f"   - results/enhanced_trading_actions.csv")
    
    print(f"\n" + "="*60)
    print(f"âœ… í™•ì¥ëœ FinRL ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!")
    print(f"="*60)
    
    return {
        'trained_model': trained_model,
        'performance': {
            'total_return': total_return,
            'cagr': cagr,
            'mdd': mdd,
            'sharpe': sharpe,
            'volatility': volatility,
            'outperformance': outperformance
        },
        'data_processor': data_processor,
        'feature_stats': {
            'total_features': len(ALL_INDICATORS),
            'tech_features': len(tech_indicators),
            'macro_features': len(macro_indicators),
            'transformer_features': len(transformer_indicators),
            'sentiment_features': len(sentiment_indicators)
        }
    }

if __name__ == "__main__":
    results = main()